
The following section introduce the relevant methodologies for conducting an event study and measuring abnormal returns on both short and long horizons. These methodologies will provide the foundation for the evaluation of shareholder reactions to events. To round up the chapter, I clarify how this paper will integrate the methods and the data foundation to investigate the reaction from shareholders to corporate events. 

\subsection{The Event Study Methodology}

On the surface, measuring the effect of an economic event is often a difficult task for economists. However, with frequent and efficient data from the financial markets, constructing an event study allows a researcher to measure the impact of an isolated event on the value of a firm.  

The methodology is used to measure the market response to corporate events. The foundation of event studies emerge from the \textit{efficient market hypothesis} \citep{fama1969_EMH}, which states that security prices reflect all present information. Given rationality on the markets, the impact of an event will be reflected immediately in the price of a security.  Within finance research, event studies has been applied to measure market reactions to firm specific events such as mergers and acquisitions and earnings announcements. Various event study methodologies has been discussed in the literature, however the baseline of my structure is centered on \citep{Event_studies}. The methodology draws on specific assumptions including semi-strong market efficiency, unanticipated events, and non-confounding events. \cite{sorescu2017event} examines the issue of confounding events
and do not find it problematic in short term event studies. For this reason, I do not eliminate overlapping events across different firms in the analysis. However, I do remove overlapping dates for individual firms in order to avoid measuring the return of a specific day more than once.

The initial task of establishing an event study is to outline the event of interest and determine the window over which the security prices will be inspected. The latter is dependent on the former, as various events require different examination time. New information related to public news, charges, and accusations may require wide windows to reflect all information. To investigate the full impact of events, I apply event windows of 21 days around an event for the short term inspection and portfolio holding periods between 1-12 months for the long term. 

Furthermore, the examination requires a measure of impact on firm performance from an event. The expected return model for long-term event studies will be introduced in subsequent sections. Concerning short-term event studies, \cite{Event_studies} outlines the appropriate measure through the "abnormal return" associated with an event, defined as the difference between the realized ex-post return and the expected return. The latter is characterized as the expected return conditional on the event not taking place, as:  
\begin{equation}
    AR_{i,t} = R_{i,t} - E[R_{i,t} \mid X_t ]
    \label{eq:AR1}
\end{equation}
where $AR_{i,t}$ is the abnormal return as the difference between the realized return, $R_{i,t}$, and the expected return, $E[R_{i,t} \mid X_t ]$, for firm \textit{i} at time \textit{t}. $X_t$ is the conditional information from an expected returns model. In the following section I explore the possibilities for measuring abnormal return on a short horizon. 

\subsection{Short Term Abnormal Returns: The Market Model} \label{market_model}

To assess the short term impact on corporate events, I examine the abnormal returns over a period covering 21 trading days surrounding an event. This window spans 10 days prior to the event, the actual event day, and 10 days following it. I include 10 days before to detect possible leakages or reactions before a spike in news articles occur. Additionally, the subsequent 10-day period helps determine if the event itself has a notable impact. To quantify the impact through abnormal returns, it is necessary to establish a model for expected returns. 

Several models have been applied in the literature to estimate the short-term abnormal returns in event studies, including the CAPM, the Market Model, and various multi-factor models. According to \cite{holler2014event} the most widely used is the Market Model, which assumes a linear relationship between the individual stock return and the market return.  The Market Model considers a single factor by linking the return of a specific security to the return of a market portfolio. Since I am analyzing the relation on European stocks, I assume the market portfolio to be the STOXX Europe 600. In this model, I assume that asset returns follow a jointly multivariate normal distribution and are independently and identically distributed over time. For a particular stock, the model is defined as follows:

\begin{equation} 
    R_{i,t} = \alpha_i + \beta_i * R_{m,t} + \epsilon_{i,t},
    \label{eq:market_model}
\end{equation}
 where $R_{i,t}$ is the return of the stock \textit{i} on day \textit{t}, $\alpha_i$ is the regression intercept\footnote{The excess return of a stock that is not explained by its sensitivity to the market return}, $R_{m,t}$ is the market return on day, and
 $\beta_i$ is the sensitivity of $R_{i,t}$ to the returns of a market portfolio.
 
The estimation window of the regression is set to 120 days prior to the event, as proposed by \cite{Event_studies}, to mitigate for sampling error and serial correlation in abnormal returns. In practical terms, this corresponds to the time frame of $[-131;-11]$ before the event, excluding the days potentially affected by the event to prevent contamination. Under the null hypothesis that the event does not affect returns, the distributional properties of the abnormal returns can be used to draw inferences in the event period. 

I apply the linear Ordinary Least Squares (OLS) in the estimation of expected returns. \cite{brown1985using} investigate the properties of applying daily stock returns in event studies. They find that the methodologies based on the OLS market model are well-specified under a variety of conditions. It is common knowledge that daily returns may suffer from non-normality. However the mean excess return in a cross-section of securities converges to normality as the amount of sample securities increase. For hypothesis tests over multi-day intervals, autocorrelation plays a minor role. An absence of clustering in events is sufficient for the requirement of a consistent variance estimator and for deeming cross-correlation irrelevant, as the abnormal returns will be independent across securities. 

As defined in equation \ref{eq:AR1}, the abnormal return is computed as the residual component between the realized return and the expected return from predicted from the Market Model in equation \ref{eq:market_model} for each event:
 \begin{equation}
    AR_{i,t} = R_{i,t} - E[R_{i,t} \mid X_t ] =  R_{i,t} - (\hat{\alpha_i} + \hat{\beta_i} * R_{m,t}).
    \label{eq: AR}
 \end{equation} 
$AR_{i,t}$ measures the shareholders' reaction to the event of firm \textit{i} at time \textit{t}. Assuming no clustering of events, the individual securities abnormal returns can be aggregated for each event period, $t = T_1 + 1, ..., T_2.$ Given N events, the sample average abnormal returns for period \textit{t} is:  
 \begin{equation}
 AAR_t = \frac{1}{N} \sum_{i=1} ^N AR_{i,t},
 \label{eq: AAR}
 \end{equation}
 and for large estimation period, its variance is
 \begin{equation}
 var(AAR_{t}) = \frac{1}{N^2} \sum_{i=1} ^N \sigma_{\epsilon_i} ^2.
  \label{eq: var}
 \end{equation}
From these estimates, I can analyze the abnormal returns for any event period. To calculate the cumulative average abnormal return (CAAR) I aggregate the AAR over the event window. For any interval in the window:
 \begin{equation}
 CAAR_{[t_1,t_2]} = \sum_{t = t_1} ^{t_2} AAR_{t},
 \label{eq: CAAR}
 \end{equation}
 \begin{equation}
 var(CAAR_{[t_1,t_2]}) = \sum^{t_2}_{t = t_1} var(AAR_{t})
 \end{equation} 
For the variance estimator, the assumption of no clustering of events is used to set the covariance terms to zero. I draw inference about the cumulative abnormal returns from $CAAR_{[t_1,t_2]} \sim N[0, var(CAAR_{[t_1,t_2]})]$ to test the null hypothesis of no abnormal performance. As $\sigma_{\epsilon_i} ^2$ is unknown in practice, I use the estimated sample variance from the Market Model, as in equation \ref{eq: var}, to calculate $ var(AAR_{t})$. A standard test statistic is the ratio of the CAAR to its estimated standard error from the Market Model. Thus, I can test the $H_0$ by using: 
 \begin{equation}
 \theta_1 = \frac{ CAAR_{[t_1,t_2]} }{ {var(CAAR_{[t_1,t_2]})}^{1/2} /\sqrt{N} } \sim(0,1)
 \label{eq: test_stat}
 \end{equation}
Where $\sigma$ is the sample standard deviation of the CAAR and N is the number of observations on a given day. The distribution is asymptotic with the number of stocks N and the length of the estimation window. Due to the large sample size, the test statistic is following a standard normal z-distribution under the null hypothesis \citep{Event_studies}. This test statistic is computed and compared to its assumed distribution under the one-sided null hypothesis, and provides the certainty to which the estimated average is lower than zero given the standard error of the observations. 

Overall, this section provides the tools to test the short term hypothesis after identifying an event. First, I estimate the expected returns from the Market Model as in equation \ref{eq:market_model}, which allows me to compute the abnormal return within the 21-day event window. Subsequently, the AAR is calculating as in equation \ref{eq: AAR} by averaging across all firms on specific days relative to the event within the 21-day window. By accumulating the AAR across the event window I find the CAAR (equation \ref{eq: CAAR) as the }overall development in market value from an event. Finally, I test the hypothesis that the CAAR, on the 21st day of the window, is equal to zero.       

\subsection{Long Term Abnormal Returns}

When transitioning from short-term to long-term measurement horizons, there are two crucial considerations in estimation of risk-adjusted returns. First, in long-term tests, even minor inaccuracies in risk adjustment can lead to substantial disparities in measured abnormal performance. This inaccuracy could be due to a company experiencing, e.g., unusual prior performance or extreme economic characteristics. To adjust for this, long-term abnormal performance is measured based on post-event risk estimates rather than historical ones. \\
Second, as the objective of event studies is to isolate the impact of an event on stock price performance, it is necessary to employ an expected return model that effectively distinguishes performance associated with the event from other known determinants of performance \cite{kothari}.   

In an evaluation of long-horizon event study methodologies, \cite{Ang_event_method} highlight two approaches which have been used substantially in the finance literature. The Buy-and-Hold Approach calculates the abnormal return as the difference between the return from the event firm and a benchmark, and tests the null hypothesis that the abnormal return is zero. Another approach, the Calendar-Time Portfolio (CTP), forms a portfolio each month consisting of firms that have experienced an event prior to the month, and tests the null hypothesis that the intercept is zero in a regression against the factors of an asset-pricing model.

However, both approaches are to some degree challenged by misspecification of test statistics. \cite{Lyon_1997_test_stats} studies the empirical power in long-term abnormal stock returns and identifies three sources for misspecification: New listing bias\footnote{The new listing bias arises since sample firms in event studies often have a long posterior history of returns, while the constituents of a reference portfolio may include firms that began trading subsequent to the event period.}, rebalancing bias\footnote{The rebalancing bias emerge since the compound returns of a reference portfolio, such as a weighed market index, are typically calculated assuming periodic rebalancing, while the returns of sample firms are compounded without rebalancing. }, and skewness bias\footnote{ the skewness bias arises because long-run returns are typically positively skewed.}. Whether these biases give rise to misspecification depends on the method used in identifying abnormal returns. 

The Buy-and-Hold approach can mitigate the new listing and rebalancing bias by applying a benchmark consisting of a single firm with similar size and book-to-market characteristics. It is possible to eliminate the skewness bias, however it requires more advanced methods, which will not be listed here. However, the approach might also suffer from cross-correlation bias, which arises because matching on firm characteristics may fail to completely remove the correlation between firm's returns. 

There are several reason to favor the Calendar-Time Portfolio over the Buy-and-Hold approach. I avoid dealing with the aforementioned biases along with the challenge associated with identifying benchmark firms for a sample of 600 firms. In addition, the specific benchmark introduces complexities in reproducing the research findings. On the other hand, while the CTP approach effectively addresses the biases mentioned earlier, it may have issues with heteroskedasticity in portfolio returns \cite{lyon1999improved}.

On the basis of these considerations, I will employ the Calendar-Time Portfolio in the evaluation of abnormal returns. The next subsection will explain the approach in more detail. 

\subsubsection{Calendar-Time Portfolio} \label{sec: CTP}

To implement the approach, a portfolio is constructed each calendar month consisting of all firms experiencing an event within the preceding \textit{T} months. In practice, the "T" will be referred to as the holding period. The monthly portfolio return is computed as the weighted average return of firms that experienced an event within the preceding T months:
\begin{equation}
    R_{p,t} = \sum_{i=1} ^{N} \frac{w_{i,t} R_{i,t} }{ w_{i,t}  } .
\end{equation}
Where $R_{p,t}$ is the portfolio returns, $R_{i,t}$ and $w_{i,t}$ is the return and weight, respectively, of stock \textit{i} in period \textit{t}, and \textit{N} is the amount of stocks in the portfolio in period \textit{t}. In order to determine whether the portfolio has achieved abnormal performance, I regress the time series of monthly portfolio excess returns on the five factors from \cite{fama2015five}: 
\begin{equation} \label{eq: FF5}
    R_{p,t} - R_{RF,t} = \alpha_p + \beta_1(R_{M,t} - R_{rf,t}) + \beta_2 SMB_t + \beta_3 HML_t + \beta_4 RMW_t + \beta_5 CMA_t \epsilon_{p,t} 
\end{equation}
where $R_{RF,t}$ and $R_{M,t}$ is the risk-free rate\footnote{U.S. one month T-bill rate} and the return of the market portfolio, respectively, at time \textit{t}. The $\beta$'s represent the sensitivity of the portfolio return towards the market portfolio and the following risk factors, which are computed as return differential between portfolios of;
\begin{itemize}
  \item $SMB_t$ = Small and large stocks in terms of market capitalization.
  \item $HML_t$ = High book-to-market and low book-to-market stocks.
  \item \textbf{$RMW_t$} = Robust and weak stocks in terms of profitability.
  \item \textbf{$CMA_t$} = Conservative and aggressive stocks in terms of investments.  
\end{itemize}

Under the assumption that the five-factor model adequately explains the variability in expected stock returns, the regression intercept, denoted as $\alpha$, measures the risk-adjusted average abnormal performance of event firms in the sample. In the absence of abnormal returns, this intercept should ideally be zero. Therefore, the accuracy of the estimation relies on the model's capacity to explain the risk factors prevalent in the market. I make inferences using a Student's \textit{t}-statistic derived from the time-series of monthly calendar-time abnormal returns. If the test results indicate that the $\alpha$ is not statistically different from zero, the time-series aligns with the asset pricing model, which implies that the event has no significant long-term impact. Conversely, if the test reveals significant $\alpha$, it suggests that the event had a long-term impact.

\cite{fama1998_events} outlines the advantages of the CTP approach as emerging from the use of monthly returns and rebalancing. Monthly returns are less skewed, which makes the model less sensitive to the bad model problem of describing average returns. Further, the monthly rebalancing captures the effect of the cross-correlation between stock returns, as companies exit and new companies enter each month. Since the number of stocks in the portfolio varies from one month to another, the error term of the regression may be heteroskedastic. For example, \cite{ritter1995} argues that anomalies can be understated if events cluster in time due to, e.g., timing of events. However, I alleviate this issue by using weighted least squares (WLS) in the regression with the monthly amount of firms as weights, as suggested by \cite{Ang_event_method}. In addition, as homoskedastic residuals may still be a harsh assumption, I compute heteroskedastic-robust standard errors from the approach of \cite{white1980heteroskedasticity}. Overall, \cite{lyon1999improved} report that the calendar-time portfolio approach together with a Fama-French factor model is well specified for random samples in their simulation study. 

Portfolio returns can be computed using either value-weighted or equal-weighted approaches. \cite{fama1998_events} recommend to employ value-weightings for event firms as it better captures the wealth effect encountered by investors. Moreover, an equal-weighted portfolio will assign relatively more weight to small stocks, which potentially amplifies the biases in asset-pricing models' ability to explain average returns. Therefore, the preferred approach is to use value weights based on market capitalization when computing portfolio returns for both short and long horizons. 

The models for short- and long-term expected returns in combination with event studies have been extensively employed to assess the impact of specific events. By leveraging these well-established techniques, I aim to uncover further insights through an innovative approach to identify and assess investor reactions. The following section describes this approach. 

\subsection{Data and General Setup}

In this section I will initially introduce the diverse datasets I will use in the analysis. Following, I will provide a thorough explanation of how and why this data can be advantageous in this specific event study.    

\subsubsection{The Data}

\textbf{SDG data.} In this study I utilize a data set called SDG Signals provided by Matter\footnote{ https://www.thisismatter.com/sdg-signals}. The company has developed a systematic collection of daily news articles from more than 150.000 media sources. It contains the volume of which individual companies are mentioned in a positive, negative, or neutral context concerning the United Nations' 17 Sustainable Development Goals (SDGs) across global news articles. The database is updated at midnight each day and employs artificial intelligence techniques to associate individual news articles with more than 75,000 publicly traded companies. It assesses the relevance of each article to a specific SDG or in a broader context. Therefore, based on the observed volume of news articles related to a specific company on a particular day, I make the assumption that it reflects the severity of the events experienced by that company. This assumption allows me to utilize the volume of daily news articles as a proxy for the significance of events.

The short-term analysis is based on daily observations and identifies an event when the number of news articles surpasses a predetermined threshold. To determine the threshold, I use a one standard deviation move from the daily average article count for a given firm. Additionally, the threshold requires the amount of positive news articles to be at least double  that of negative news articles, and vice versa. This criteria is implemented in order to avoid misleading events, as the amount of negative articles is generally lower than positive ones. Without this assumption, a considerable number of non-events would be identified in the sample. Moreover, news articles published on a Saturday or Sunday are attributed to the following Monday, as the stock price response will manifest here. This approach carries the risk of artificially inflating the number of observed articles on Mondays, so I mitigate this potential skewness by dividing the count of articles on Mondays by three to level the effects. To ensure the accuracy of the analysis, I decontaminate the daily count of news articles for each company by subtracting the number of irrelevant articles from the total count. 

\noindent \textbf{Company data.} To investigate the validity of the hypotheses on the European financial markets, I select all the constituents of the \textit{STOXX Europe 600} index from January 2018 to January 2023, that were actively traded on January 1, 2018. This index represents approximately 90\% of the market capitalization of the developed European equity market. After excluding companies that did not experience any events on a daily or monthly basis, the dataset consists of a total of N = 437 stocks. Hence, more than two-thirds of the sample firms experienced at least one event during this period. Daily and monthly market capitalization\footnote{I use the free-float market capitalization calculated in Euro to best reflect the market movements} and returns, adjusted for stock splits and dividends, are collected from Bloomberg\footnote{https://www.bloomberg.com.}. 

Additionally, I extend the dataset to include ESG Risk Ratings provided by Sustainalytics\footnote{https://www.sustainalytics.com/esg-ratings. The ratings are the contemporaneous ratings and not a historical time series. However, as the analyzed period simply spans five years, I assume that the actual changes in ratings would not affect my results significantly.}. These ratings assess the level of ESG risk for individual firms, categorizing them as negligible, low, medium, high, or severe. Due to the limited number of firms in the negligible and severe groups, they are added to the low and high groups, respectively, to exploit the data fully. 

\subsubsection{The Event Study}

When conducting an event study, researchers commonly construct their databases by either collecting events from archives or utilizing existing databases that comprise a thoughtfully selected set of events, for example \cite{flammer2013corporate}. However, both approaches share a limitation in that they rely on hand-picked events, which undermine the practical use cases of these results. \\
First, the fact that events are defined ex-post introduces a potential bias in the selection of events for the sample. This bias may arise because sampled events are typically chosen based on desirable characteristics and outcomes, while inadvertently excluding less significant events. However, the excluded events may have been significant from a shareholder's perspective in real-time. This bias can potentially skew the representation of events. Second, although short-term reactions to well-defined events are empirically evident, practitioners are unable to capitalize on these circumstances. The identification of events relies on information that, in certain situations, may not be available at the time of action. Hence, while we can measure an event ex-post, we lack the ability to react to it in real-time. 

Accordingly, I attempt to overcome this concern by identifying events based SDG news data, as mentioned in the former section. Therefore, the specific events examined in this study are not explicitly defined within the dataset itself. Instead, I employ a rule-based approach to identify significant spikes in the volume of news articles related to individual companies. 

The short term methodology produces 1.618 negative events and 10.275 positive events during the five year period. For the long-term analysis, I follow a similar approach but aggregate the daily news articles into monthly figures, upon which events are identified based on significant spikes in the monthly sum. Using this method, I identify a total of 1.117 negative events and 2.054 positive events. The events are evenly distributed throughout the period, with the exception of the initial months of the COVID-19 pandemic, as illustrated in figure \ref{fig:event_distribution} in the appendix. The distribution is sufficient evidence to confirm that events are not clustering in calendar time. Moreover, figure \ref{fig:event_distribution_SDG} in the appendix shows the events are not evenly distributed across sustainability goals, as SDG 3, 7, 12, 13, and 16 receive considerably more media attention than the remainders. The amount of events increases considerably when conditioning on the various SDGs, as this involves the possibility of several events per day. 

Overall, this chapter provides a demonstration of the methods and steps involved in conducting this type of event study. 
Specifically, we discussed the use of a Market Model to estimate short term abnormal returns and the Calendar-Time portfolio approach to construct monthly portfolio returns evaluated by a regression on the Fama-French factors. In both instances, I identify significant events as a significant spike in news articles by using the methodology described above on either a daily or monthly basis, and compute the corresponding abnormal returns by the Market Model or the CTP. The results from these estimations are presented in the following chapter. 