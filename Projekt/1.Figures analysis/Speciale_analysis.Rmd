---
title: "Speciale_analysis"
author: "Martin Andersen"
date: "2023-02-13"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r,message=FALSE}
# Load packages:
library(tidyverse)
library(lubridate)
library(readxl)
library(timetk)
library(dplyr)
library(zoo)
library(furrr)
library(ggplot2)
library(ggpubr)
library(xtable)
library(purrr)
library(stringr)
library(magrittr)
library(BSDA)
library(scales)
library(generics)

source("functions.R")

# STOXX 600 Europe index 
sxxp_index_daily <- read.csv("C:/Users/Marti/OneDrive - University of Copenhagen/KU/Speciale/Data behandling/STOXX_600_INDEX.csv", 
                             sep = ",") %>%
  transmute(date = as.Date(Date, format = "%m/%d/%Y"),
         mkt_excess = as.numeric(gsub('%','',Change..))/100)

# Sentiment and stock data merged together with daily observations
data_daily <- read.csv("C:/Users/Marti/OneDrive - University of Copenhagen/KU/Speciale/Data behandling/data_daily.csv", sep = ",")  %>% 
  mutate(date = as.Date(date)) %>% select(-X)

# Sentiment and stock data merged together with weekly observations
data_weekly <- read.csv("C:/Users/Marti/OneDrive - University of Copenhagen/KU/Speciale/Data behandling/all_data_week.csv", sep = ",") %>%
  mutate(date = as.Date(date)) %>% select(-X)

```

#################################
### Data for monthly returns:
#################################
```{r} 
# Data connection to get STOXX 600 Europe sentiment and stock data. Joined on stock data, so there will be NA's in the sentiment.  
 
eu_3factors_daily <- read.csv("C:/Users/Marti/OneDrive - University of Copenhagen/KU/Speciale/Data behandling/Europe_3_Factors_Daily.csv", sep = ",") %>% 
  transmute(date = as.Date(ymd(X)),
         mkt_excess = Mkt.RF/100,
         SMB = SMB/100,
         HML = HML/100,
         RF = RF/100)

eu_5factors_daily <- read.csv("C:/Users/Marti/OneDrive - University of Copenhagen/KU/Speciale/Data behandling/Europe_5_Factors_Daily.csv", sep = ",") %>% 
  transmute(date = as.Date(ymd(X)),
         mkt_excess = Mkt.RF/100,
         SMB = SMB/100,
         HML = HML/100,
         RMW = RMW/100,
         CMA = CMA/100,
         RF = RF/100)



long_term_data_weekly <- data_weekly %>%
  transmute(date,isin,MKT_CAP, 
            ret = W_RETURN, 
            norm_positive_sum = sentiment_positive_count - sdg_not_relevant_positive_count,
            norm_negative_sum = sentiment_negative_count - sdg_not_relevant_negative_count,
            ) %>%
  group_by(isin) %>%
  transmute(date,isin,ret,MKT_CAP,
    norm_positive_sum = replace_na(norm_positive_sum,0),
    norm_negative_sum = replace_na(norm_negative_sum,0),
    roll_mean = across(!c(date,ret,MKT_CAP),
                      ~ rollmean(.x, k = 3, fill = NA, align = "right"))) %>%
  unnest(roll_mean,names_sep = "_") %>% arrange(isin) %>%
  group_by(isin) %>%
    mutate(
    roll_mean_positive = na_if(roll_mean_norm_positive_sum, 0), 
    roll_mean_negative = na_if(roll_mean_norm_negative_sum, 0),
    positive_threshold = mean(roll_mean_positive,na.rm = TRUE) + 2*sd(roll_mean_positive,na.rm = TRUE),
    negative_threshold = mean(roll_mean_negative,na.rm = TRUE) + 2*sd(roll_mean_negative,na.rm = TRUE)
    ) %>%
  group_by(date,isin) %>%
  # Make sure that we only calculate the cutoff value of periods with actual observations. 
  mutate(pos_event = 
    case_when(roll_mean_positive > positive_threshold & roll_mean_positive > 5 & roll_mean_positive > 1*roll_mean_norm_negative_sum ~ 1,
              TRUE ~ 0),
    neg_event = 
    case_when(roll_mean_negative > negative_threshold & roll_mean_negative > 5 & roll_mean_negative > 1*roll_mean_norm_positive_sum ~ 1, 
              TRUE ~ 0)
    ) 
```

################ 
Calendar-time portfolio approach 1 week sentiment data: 
################

```{r}


###########################
# Positive events:
###########################

long_term_data_weekly_positive = long_term_data_weekly

# Add lagged values of the events to sort whether an event has happened in the last X months. 
  for (i in 1:12) {
  long_term_data_weekly_positive[paste0("-",i)] <- long_term_data_weekly_positive %>% group_by(isin) %>% transmute(t = lag(pos_event,i)) %>% ungroup() %>% select(-isin)
  }


long_term_data_positive = long_term_data_weekly_positive %>% select(date,isin,ret,MKT_CAP,contains("-")) %>%
  pivot_longer(!c(date,isin,ret,MKT_CAP), names_to = "period", values_to = "event") %>%
  mutate(period = as.numeric(period)) %>%
  filter(event == '1') %>%
    # Remove duplicate rows of the returns in case one ISIN pops up on several dates. 
  group_by(date,isin) %>% distinct(ret, .keep_all = TRUE)

# x Month portfolio returns:

list = list(1,3,6,12)
alpha_positive <- data.frame(matrix(nrow=4, ncol=5)) 
colnames(alpha_positive)<-c("Alpha","t","p" ,"return", "model")

for (x in 1:length(list)) {
  
  i = list[[x]]

long_term_data_M_positive = long_term_data_positive %>%
  # Only include the last 1 months:
  filter(period >= -i) %>%
  group_by(date) %>%
  summarise(ret = weighted.mean(ret,MKT_CAP)) %>%
  left_join(eu_3factors_daily, by = "date")

# Calculate alpha of portfolios:
  
alpha_M_positive = long_term_data_M_positive %>% 
   summarise(alpha = tidy(lm(ret ~ 1 + mkt_excess + SMB + HML))$estimate[1],
             t = tidy(lm(ret ~ 1 + mkt_excess + SMB + HML))$statistic[1],
             p = tidy(lm(ret ~ 1 + mkt_excess + SMB + HML))$p.value[1],
             return = mean(ret)) %>%
   mutate(model = paste0(i,"M")) 

alpha_positive[x,] = alpha_M_positive

# Plot the returns:
long_term_data_M_positive %>%
  ggplot(aes(x = date, y = ret)) + 
   geom_bar(stat = 'identity') + 
   geom_smooth(method = "lm") +
    theme_bw() +
   labs(x = "", y = "Monthly Returns") +
    scale_y_continuous(breaks = pretty_breaks(),
                     labels = scales::percent) +
   scale_x_date(date_breaks = "1 years", date_labels = "%Y" )
      ggsave(paste0("LT_positive_returns_", i,".png"))
}

print(xtable(alpha_positive %>% relocate(model),type="latex",
             digits=c(0,4,4,4,4,4),
             hline.after=c(-1,0),
             floating=FALSE,latex.environments=NULL),
      include.rownames=FALSE,
      include.colnames = TRUE) %>% 
  write(file="alpha_positive.tex")

############################
# Negative events:
############################

long_term_data_weekly_negative = long_term_data_weekly

# Add lagged values of the events to sort whether an event has happened in the last X months. 
  for (i in 1:12) {
  long_term_data_weekly_negative[paste0("-",i)] <- long_term_data_weekly_negative %>% group_by(isin) %>% transmute(t = lag(neg_event,i)) %>% ungroup() %>% select(-isin)
  }

long_term_data_negative = long_term_data_weekly_negative %>% select(date,isin,ret,MKT_CAP,contains("-")) %>%
  pivot_longer(!c(date,isin,ret,MKT_CAP), names_to = "period", values_to = "event") %>%
  mutate(period = as.numeric(period)) %>% 
  filter(event == '1') %>%
    # Remove duplicate rows of the returns in case one ISIN pops up on several dates. 
  group_by(date,isin) %>% distinct(ret, .keep_all = TRUE)


# x Month portfolio returns:

list = list(1,3,6,12)
alpha_negative <- data.frame(matrix(nrow=4, ncol=5)) 
colnames(alpha_negative)<-c("Alpha","t","p" ,"return", "model")

for (x in 1:length(list)) {
  
  i = list[[x]]

long_term_data_M_negative = long_term_data_negative %>%
  # Only include the last 1 months:
  filter(period >= -i) %>%
  group_by(date) %>%
  summarise(ret = weighted.mean(ret,MKT_CAP)) %>%
  left_join(eu_3factors_daily, by = "date")

# Calculate alpha of portfolios:
  
alpha_M_negative = long_term_data_M_negative %>% 
   summarise(alpha = tidy(lm(ret ~ 1 + mkt_excess + SMB + HML))$estimate[1],
             t = tidy(lm(ret ~ 1 + mkt_excess + SMB + HML))$statistic[1],
             p = tidy(lm(ret ~ 1 + mkt_excess + SMB + HML))$p.value[1],
             return = mean(ret)) %>%
   mutate(model = paste0(i,"M")) 

alpha_negative[x,] = alpha_M_negative

# Plot the returns:
long_term_data_M_negative %>%
  ggplot(aes(x = date, y = ret)) + 
   geom_bar(stat = 'identity') + 
   geom_smooth(method = "lm") +
    theme_bw() +
   labs(x = "", y = "Monthly Returns") +
    scale_y_continuous(breaks = pretty_breaks(),
                     labels = scales::percent) +
   scale_x_date(date_breaks = "1 years", date_labels = "%Y" )
      ggsave(paste0("LT_negative_returns_", i,".png"))
}

print(xtable(alpha_negative %>% relocate(model),type="latex",
             digits=c(0,4,4,4,4,4),
             hline.after=c(-1,0),
             floating=FALSE,latex.environments=NULL),
      include.rownames=FALSE,
      include.colnames = TRUE) %>% 
  write(file="alpha_negative.tex")


pp_data
```

################ 
Parametric portfolio approach 1 week sentiment data: 
################

```{r}

pp_data = long_term_data_weekly %>% select(date, isin, ret, MKT_CAP, pos_event,neg_event) %>%
  group_by(isin) %>%
  mutate(
    month = date,
    ret_excess = ret,
    permno = isin,
    MKT_CAP = MKT_CAP/1000000000,
    mktcap_lag = lag(MKT_CAP)) %>%
  na.omit()
  
pp_monthly_lags = pp_data %>% 
  group_by(isin) %>%
  transmute(isin,
            date_5 = lead(date,5),
            MKT_CAP) 

pp_data = pp_data %>% 
  inner_join(pp_monthly_lags,
             by = c("isin","date" = "date_5"),
             suffix = c("", "_5"))
  
data_portfolios = pp_data %>%
  mutate(
    momentum_lag = mktcap_lag / MKT_CAP_5,
    size_lag = log(mktcap_lag),
    event = neg_event
    ) %>%
  drop_na(contains("lag"))


data_portfolios = data_portfolios %>%
  group_by(date) %>%
  mutate(
    n = n(),
    relative_mktcap = mktcap_lag / sum(mktcap_lag),
    across(contains("lag"), ~ (. - mean(.)) / sd(.)),
    ) %>%
  ungroup() %>%
  select(-mktcap_lag)

n_parameters <- sum(str_detect(colnames(data_portfolios), "lag"))

theta <- rep(1.5, n_parameters)

names(theta) <- colnames(data_portfolios)[str_detect(
  colnames(data_portfolios), "lag")]


weights <- compute_portfolio_weights(
  optimal_theta,
  data_portfolios,
  value_weighting = TRUE,
  allow_short_selling = FALSE
)

power_utility <- function(r, gamma = 5) {
  (1 + r)^(1 - gamma) / (1 - gamma)
}

evaluate_portfolio(weights) |>
  print(n = Inf)




optimal_theta <- optim(
  par = theta,
  compute_objective_function,
  objective_measure = "Expected utility",
  data = data_portfolios,
  value_weighting = TRUE,
  allow_short_selling = FALSE
)

optimal_theta = optimal_theta$par
```



################ 
Short term abnormal return after an individual event - Daily 
################

```{r}


short_term_data_daily = data_daily %>% 
  mutate(date = as.Date(date)) %>% 
  right_join(sxxp_index_daily %>% select(date, mkt_excess), by = "date")

# 
#  plan(multisession, workers = availableCores())
# 
#  short_term_data_nested <- short_term_data_daily %>% ungroup() %>%
#    select(date,isin,W_RETURN,mkt_excess) %>%
#    nest(data = -c(isin)) %>%
#    mutate(beta = future_map(
#      data, ~ roll_capm_estimation(., window = 120, min_obs = 80, period = "day")
#    )) %>%
#    unnest(c(beta)) %>%
#    na.omit(beta,alpha) %>% select(-data)


  # Write to CSV to keep in nice format:
       short_term_data_nested %>%
           write.csv(file = "C:/Users/Marti/OneDrive - University of Copenhagen/KU/Speciale/Data behandling/nested_daily_for_capm_sxxp.csv")

 betas <- read.csv("C:/Users/Marti/OneDrive - University of Copenhagen/KU/Speciale/Data behandling/nested_daily_for_capm_sxxp.csv", sep = ",") %>%
   select(-X) %>%
   mutate(date = as.Date(date))

 
short_term_data <- betas %>% 
  left_join(short_term_data_daily, by = c("date","isin")) %>%
  group_by(isin) %>%
  mutate(
      pred_ret = alpha + beta*mkt_excess,
      abnormal_ret = W_RETURN - pred_ret,
      norm_positive_sum = sentiment_positive_count - sdg_not_relevant_positive_count,
      norm_negative_sum = sentiment_negative_count - sdg_not_relevant_negative_count#,
  #     
  #     roll_sum = across(!c(date,sdg_not_relevant_positive_count,sdg_not_relevant_negative_count,beta,alpha,W_RETURN,negative_sum,
  #                     positive_sum,mkt_excess,pred_ret,abnormal_ret,sentiment_positive_count,sentiment_negative_count),
  #                     ~ rollsum(.x, k = 5, fill = NA, align = "right"))) %>% 
  # unnest(roll_sum,names_sep = "_") %>%
     
  ) %>%
  select(-c(beta,alpha,pred_ret,sdg_not_relevant_positive_count,sdg_not_relevant_negative_count))

remove(short_term_data_daily,short_term_data_nested,betas,short_term_data_sdg,sentiment_daily,data_daily,sxxp_index_daily,msci_index_daily)

# Create columns that represent the lagged and leading values in relation to the event date:


for (i in 1:10) {
  short_term_data[paste0("-",i)] <- short_term_data %>% group_by(isin) %>% transmute(t = lag(abnormal_ret,i)) %>% ungroup() %>% select(-isin)
  short_term_data[paste0("+",i)] <- short_term_data %>% group_by(isin) %>% transmute(t = lead(abnormal_ret,i)) %>% ungroup() %>% select(-isin)
  
  short_term_data[paste0("neg_event_-",i)] <- short_term_data %>% group_by(isin) %>% transmute(l = lag(norm_negative_sum,i)) %>% ungroup() %>% select(-isin)
  short_term_data[paste0("neg_event_+",i)] <- short_term_data %>% group_by(isin) %>% transmute(l = lead(norm_negative_sum,i)) %>% ungroup() %>% select(-isin)

  short_term_data[paste0("pos_event_-",i)] <- short_term_data %>% group_by(isin) %>% transmute(l = lag(norm_positive_sum,i)) %>% ungroup() %>% select(-isin)
  short_term_data[paste0("pos_event_+",i)] <- short_term_data %>% group_by(isin) %>% transmute(l = lead(norm_positive_sum,i)) %>% ungroup() %>% select(-isin)
}

short_term_data_event = short_term_data %>%
  group_by(isin) %>%
  mutate(
    norm_positive_sum = na_if(norm_positive_sum, 0),
    norm_negative_sum = na_if(norm_negative_sum, 0),
    positive_threshold = mean(norm_positive_sum,na.rm = TRUE) + 1*sd(norm_positive_sum,na.rm = TRUE),
    negative_threshold = mean(norm_negative_sum,na.rm = TRUE) + 1*sd(norm_negative_sum,na.rm = TRUE)
    ) %>%
  rename("0" = abnormal_ret) %>%
  
   select(-c("W_RETURN","mkt_excess",
             #"positive_threshold","negative_threshold","norm_positive_sum","norm_negative_sum",
              "sentiment_negative_count","sentiment_positive_count",
             #"roll_mean_norm_negative_sum","roll_mean_norm_positive_sum", "roll_sum_norm_negative_sum","roll_sum_norm_positive_sum"
             )) %>%

  group_by(date,isin) %>%
  # Make sure that we only calculate the cutoff value of periods with actual observations. 
  mutate(pos_event = 
    case_when(norm_positive_sum > positive_threshold & norm_positive_sum > 10 & norm_positive_sum > 2*norm_negative_sum ~ 1,
              TRUE ~ 0),
    neg_event = 
    case_when(norm_negative_sum > negative_threshold & norm_negative_sum > 10 & norm_negative_sum > 2*norm_positive_sum ~ 1, 
              TRUE ~ 0)
    ) 

#Splitting events into positive and negative, and cleaning the data

# Positive 
positive_index = short_term_data_event %>% 
  select(date,isin,"0",contains("-"),contains("+"),pos_event) %>% 
  select(-c(contains("pos_event_"),contains("neg_event_"))) %>%
  filter(pos_event == 1) %>%
  select(-pos_event) %>%
  pivot_longer(!c(date,isin), names_to = "type", values_to = "value") %>%
  na.omit(value) 
  

positive_index_events_mean = short_term_data_event %>% select(date,isin,pos_event,norm_positive_sum, contains("pos_event")) %>%
  filter(pos_event == 1) %>% 
  rename('0' = norm_positive_sum) %>%
  select(-pos_event) %>%
  pivot_longer(!c(date,isin), names_to = "type", values_to = "amount") %>%
   mutate_at("type", str_replace, "pos_event_", "") %>%
  group_by(isin, date)

positive_index_events = positive_index_events_mean %>%
  left_join(positive_index_events_mean %>% filter(type == '0') %>% select(isin,date,"mean" = amount), by = c("isin","date")) %>%
  mutate(amount = ifelse(is.na(amount), 0, amount)) %>%
  mutate(relative_events = amount/mean) 

positive_index_all = positive_index %>%
  left_join(positive_index_events %>% select(isin,date,type,relative_events), by = c("isin","date","type")) %>%
  mutate(type = factor(type, levels = c("-10", "-9","-8","-7","-6","-5","-4","-3","-2","-1",
                                        "0", "+1", "+2","+3","+4","+5","+6","+7","+8","+9","+10"))) %>%
  arrange(isin,date,type) %>%
  group_by(isin,date)

remove(positive_index_events_mean,positive_index_events)



### negative 

negative_index = short_term_data_event %>% 
  select(date,isin,"0",contains("-"),contains("+"),neg_event) %>% 
  select(-c(contains("pos_event_"),contains("neg_event_"))) %>%
  filter(neg_event == 1) %>%
  select(-neg_event) %>%
  pivot_longer(!c(date,isin), names_to = "type", values_to = "value") %>%
  na.omit(value) 
  

negative_index_events_mean = short_term_data_event %>% select(date,isin,neg_event,norm_negative_sum, contains("neg_event")) %>%
  filter(neg_event == 1) %>% 
  rename('0' = norm_negative_sum) %>%
  select(-neg_event) %>%
  pivot_longer(!c(date,isin), names_to = "type", values_to = "amount") %>%
   mutate_at("type", str_replace, "neg_event_", "") %>%
  group_by(isin, date)

negative_index_events = negative_index_events_mean %>%
  left_join(negative_index_events_mean %>% filter(type == '0') %>% select(isin,date,"mean" = amount), by = c("isin","date")) %>%
  mutate(amount = ifelse(is.na(amount), 0, amount)) %>%
  mutate(relative_events = amount/mean) 

negative_index_all = negative_index %>%
  left_join(negative_index_events %>% select(isin,date,type,relative_events), by = c("isin","date","type")) %>%
  mutate(type = factor(type, levels = c("-10", "-9","-8","-7","-6","-5","-4","-3","-2","-1",
                                        "0", "+1", "+2","+3","+4","+5","+6","+7","+8","+9","+10"))) %>%
  arrange(isin,date,type) %>%
  group_by(isin,date)

remove(negative_index_events_mean,negative_index_events)

### 10 days around the event: 

positive_index_10 = positive_index_all %>% 
  mutate(csum = cumsum(value)) %>%
  group_by(type) %>%
  summarise(
    rel_events = mean(relative_events, na.rm = TRUE),
    AAR = mean(value),
    CAAR = mean(csum),
    SE_AAR = sd(value, na.rm = TRUE)/sqrt(n()),
    SE_CAAR = sd(csum, na.rm = TRUE)/sqrt(n())
    )

negative_index_10 = negative_index_all %>% 
  mutate(csum = cumsum(value)) %>%
  group_by(type) %>%
  summarise(
    rel_events = mean(relative_events, na.rm = TRUE),
    AAR = mean(value),
    CAAR = mean(csum),
    SE_AAR = sd(value, na.rm = TRUE)/sqrt(n()),
    SE_CAAR = sd(csum, na.rm = TRUE)/sqrt(n())
    )
 
 # Plots

  positive_index_10 %>% select(type,AAR,CAAR,rel_events) %>%
    transmute("Relative # events" = rel_events/100,type,AAR,CAAR) %>%
    pivot_longer(!c(type), names_to = "metric", values_to = "ret") %>%
    left_join(
     positive_index_10 %>% select(type, "AAR" = SE_AAR, "CAAR" = SE_CAAR) %>% 
       pivot_longer(!c(type), names_to = "metric", values_to = "SE"), by = c("metric","type")
     ) %>%
    mutate(
     low = ret - 1.96*SE,
     high = ret + 1.96*SE
   ) %>%
    group_by(metric) %>%
    ggplot(aes(x = type, y = ret,colour = metric, group = metric)) +
    geom_bar(data = ~ filter(.x, metric %in% c("Relative # events")),
             aes(x=type, y=ret), stat = "identity", color="grey", fill="grey",
             alpha=0.05, width = 1) +
      
      geom_ribbon(data = ~ filter(.x, metric %in% c("CAAR", "AAR")),
                  aes(ymin = low, ymax = high, fill = metric),
                 alpha=0.3, linetype="dashed", show.legend = FALSE) +
    geom_line(data = ~ filter(.x, metric %in% c("CAAR", "AAR")),
              size=1) + 
    theme_bw() +
   theme(legend.title = element_blank(),
          legend.position="top",
          legend.direction = "horizontal") +
  scale_y_continuous(name ="Abnormal return",
                     breaks = pretty_breaks(),
                     labels = scales::percent, 
                     sec.axis=sec_axis(
                       breaks = c(0,0.5,1),
                       ~.*100,name="Relative events")) +
  scale_x_discrete(name = "Relative time",breaks=c("-10","-5","0","+5","+10"))
      ggsave("ST_positive_all_CI.png")
  
  
negative_index_10 %>% select(type,AAR,CAAR,rel_events) %>%
    transmute("Relative # events" = rel_events/100,type,AAR,CAAR) %>%
    pivot_longer(!c(type), names_to = "metric", values_to = "ret") %>%
    left_join(
     negative_index_10 %>% select(type, "AAR" = SE_AAR, "CAAR" = SE_CAAR) %>% 
       pivot_longer(!c(type), names_to = "metric", values_to ="SE"), by = c("metric","type")) %>%
    mutate(
     low = ret - 1.96*SE,
     high = ret + 1.96*SE
   ) %>%
    group_by(metric) %>%
    ggplot(aes(x = type, y = ret,colour = metric, group = metric)) +
    geom_bar(data = ~ filter(.x, metric %in% c("Relative # events")),
             aes(x=type, y=ret), stat = "identity",color="grey", fill="grey",
             alpha=0.05, width = 1) +
    geom_ribbon(data = ~ filter(.x, metric %in% c("CAAR", "AAR")),
                  aes(ymin = low, ymax = high, fill = metric),
                 alpha=0.3, linetype="dashed", show.legend = FALSE) +
    
    geom_line(data = ~ filter(.x, metric %in% c("CAAR", "AAR")),
              size=1) + 
    theme_bw() +
    theme(legend.title = element_blank(),
          legend.position="top",
          legend.direction = "horizontal") +
  scale_y_continuous(name ="Abnormal return",
                     breaks = pretty_breaks(n = 8),
                     labels = scales::percent, 
                     sec.axis=sec_axis(
                       breaks = c(0,0.5,1),
                       ~.*100,name="Relative events")) +
  scale_x_discrete(name = "Relative time",breaks=c("-10","-5","0","+5","+10"))
ggsave("ST_negative_all_CI.png")


```

################ 
Short term abnormal return 10 days before-after an individual event - Daily split on SDG's 
################

```{r}
 # Use the data from above chunk

short_term_data_sdg <- betas %>% 
  left_join(short_term_data_daily, by = c("date","isin")) %>%
  group_by(isin) %>%
  mutate(
      pred_ret = alpha + beta*mkt_excess,
      abnormal_ret = W_RETURN - pred_ret
  ) %>%
  select(-c(beta,alpha,pred_ret,sdg_not_relevant_positive_count,sdg_not_relevant_negative_count))


short_term_data_event_sdg = short_term_data_sdg %>% 
  select(isin,date,abnormal_ret, contains("sdg")) %>% 
  select(isin,date,abnormal_ret, contains("tive"),-c(sdg_broad_negative_count,sdg_broad_neutral_count,sdg_broad_positive_count))

remove(short_term_data_sdg,sentiment_daily,data_daily,betas,)
# Create columns that represent the lagged and leading values in relation to the event date:

for (i in 1:10) {
  short_term_data_event_sdg[paste0("-",i)] <- short_term_data_event_sdg %>% group_by(isin) %>% transmute(t = lag(abnormal_ret,i)) %>% ungroup() %>% select(-isin)
  short_term_data_event_sdg[paste0("",i)] <- short_term_data_event_sdg %>% group_by(isin) %>% transmute(t = lead(abnormal_ret,i)) %>% ungroup() %>% select(-isin)
}

# Create the threshold and filter only firms that have a significant event:

short_term_return_sdg = short_term_data_event_sdg %>%
  pivot_longer(!c(date,isin,abnormal_ret,'-1':'10'), names_to = "sdg", values_to = "value") %>%
  group_by(isin,sdg) %>%
  mutate(
      value = na_if(value, 0),
      sd = sd(value,na.rm = TRUE),
      mean = mean(value, na.rm = TRUE),
      
    threshold = mean + 1*sd
  ) %>% 
  mutate(event = 
    case_when(value > threshold & value > 3 ~ 1,
              TRUE 
               ~ 0)
    ) %>%
  rename('0' = abnormal_ret) %>%
  select(-c(value,sd,mean,threshold)) %>% 
  filter(event == 1) %>%
  mutate(group = case_when(grepl("pos", sdg) ~ "positive",
                            grepl("nega", sdg) ~"negative"),
         )
  

# Splitting up positive and negative events:

positive_index_sdg = short_term_return_sdg %>%
  filter(group == 'positive') %>%
  mutate_at("sdg", str_replace, "_positive_count", "") %>%
  mutate_at("sdg", str_replace, "_", " ") %>%
  mutate(sdg = factor(sdg, levels = c("sdg 1", "sdg 2","sdg 3","sdg 4","sdg 5","sdg 6","sdg 7","sdg 8","sdg 9","sdg 10","sdg 11", 
                                        "sdg 12", "sdg 13","sdg 14","sdg 15","sdg 16","sdg 17"))) %>%
  select(-c(event,group)) %>%
  pivot_longer(!c(date,isin,sdg), names_to = "period", values_to = "abnormal_ret") %>% na.omit(abnormal_ret) %>%
  group_by(sdg,period) %>%
    mutate(period = as.factor(period)) %>%
  summarise(AAR = mean(abnormal_ret)) %>%
  mutate( event = "positive",
    period = factor(period, levels = c("-10", "-9","-8","-7","-6","-5","-4","-3","-2","-1","0", "1", "2","3","4","5","6","7","8","9","10"))) %>%
  arrange(sdg,period) %>%
  mutate(CAAR = cumsum(AAR))


negative_index_sdg = short_term_return_sdg %>%
  filter(group == 'negative') %>%
  mutate_at("sdg", str_replace, "_negative_count", "") %>%
  mutate_at("sdg", str_replace, "_", " ") %>%
  mutate(sdg = factor(sdg, levels = c("sdg 1", "sdg 2","sdg 3","sdg 4","sdg 5","sdg 6","sdg 7","sdg 8","sdg 9","sdg 10","sdg 11", 
                                        "sdg 12", "sdg 13","sdg 14","sdg 15","sdg 16","sdg 17"))) %>%
  select(-c(event,group)) %>%
  pivot_longer(!c(date,isin,sdg), names_to = "period", values_to = "abnormal_ret") %>% na.omit(abnormal_ret) %>%
  group_by(sdg,period) %>%
    mutate(period = as.factor(period)) %>%
  summarise(AAR = mean(abnormal_ret)) %>%
  mutate( event = "negative",
    period = factor(period, levels = c("-10", "-9","-8","-7","-6","-5","-4","-3","-2","-1","0", "1", "2","3","4","5","6","7","8","9","10"))) %>%
  arrange(sdg,period) %>%
  mutate(CAAR = cumsum(AAR))


# Plots of all SDGs

positive_index_sdg %>% 
  ggplot(aes(x = period, y = CAAR, group = factor(sdg), colour = factor(sdg))) + 
  geom_line() +
  theme_bw() +
    theme(legend.title = element_blank(),
          legend.key.size = unit(0.5, 'cm')) +
  scale_y_continuous(name ="Abnormal return",
                     labels = scales::percent) + 
  scale_x_discrete(name = "Relative time",breaks=c("-10","-5","0","5","10"))
ggsave("ST_positive_sdgs.png")

  
negative_index_sdg %>% 
  ggplot(aes(x = period, y = CAAR, group = factor(sdg), colour = factor(sdg))) + 
  geom_line() +
  theme_bw() +
    theme(legend.title = element_blank(),
          legend.key.size = unit(0.5, 'cm')) +
  scale_y_continuous(name ="Abnormal return",
                     labels = scales::percent) + 
  scale_x_discrete(name = "Relative time",breaks=c("-10","-5","0","5","10"))
ggsave("ST_negative_sdgs.png")

## Bar plot of all SDGs

n_positive = short_term_return_sdg %>%
  filter(group == 'positive') %>%
  mutate_at("sdg", str_replace, "_positive_count", "") %>%
  mutate_at("sdg", str_replace, "_", " ") %>%
  mutate(sdg = factor(sdg, levels = c("sdg 1", "sdg 2","sdg 3","sdg 4","sdg 5","sdg 6","sdg 7","sdg 8","sdg 9","sdg 10","sdg 11", 
                                        "sdg 12", "sdg 13","sdg 14","sdg 15","sdg 16","sdg 17"))) %>%
  select(-c(event,group)) %>%
  pivot_longer(!c(date,isin,sdg), names_to = "period", values_to = "abnormal_ret") %>% na.omit(abnormal_ret) %>%
  mutate(period = factor(period, levels = c("-10", "-9","-8","-7","-6","-5","-4","-3","-2","-1","0", "1", "2","3","4","5","6","7","8","9","10"))) %>%
  arrange(isin,sdg,date,period) %>%
  group_by(isin,sdg,date) %>%
  mutate(CAAR = cumsum(abnormal_ret)) %>%
  group_by(sdg) %>% filter(period == '10') %>%
  summarise(n = n(),
            sd = sd(CAAR),
            se = sd/sqrt(n),
            t = 1.96,
            CI=t*se
            )
      
positive_index_sdg %>% 
  group_by(sdg) %>% 
  summarise(
  sum = sum(AAR)) %>%
  left_join(n_positive, by = "sdg") %>%
  ggplot(
    aes(x = sdg, y = sum, color= sdg,group = sdg, fill = sdg)) + 
  geom_bar(stat="identity") +
  geom_errorbar( aes(x=sdg, ymin=sum-CI, ymax=sum+CI), colour = "orange", width=0.5, alpha=0.8, size=0.7) + 
  scale_y_continuous(name ="Abnormal return",
                     labels = scales::percent) +
  theme_bw() +
  theme(legend.title = element_blank(),
        legend.key.size = unit(0.5, 'cm'),
        axis.text.x = element_text(angle=45))
ggsave("ST_positive_sdg_bar.png")

n_negative = short_term_return_sdg %>%
  filter(group == 'negative') %>% 
  mutate_at("sdg", str_replace, "_negative_count", "") %>%
  mutate_at("sdg", str_replace, "_", " ") %>%
  mutate(sdg = factor(sdg, levels = c("sdg 1", "sdg 2","sdg 3","sdg 4","sdg 5","sdg 6","sdg 7","sdg 8","sdg 9","sdg 10","sdg 11", 
                                        "sdg 12", "sdg 13","sdg 14","sdg 15","sdg 16","sdg 17","sdg broad"))) %>%
  select(-c(event,group)) %>%
  pivot_longer(!c(date,isin,sdg), names_to = "period", values_to = "abnormal_ret") %>% na.omit(abnormal_ret) %>%
  mutate(period = factor(period, levels = c("-10", "-9","-8","-7","-6","-5","-4","-3","-2","-1","0", "1", "2","3","4","5","6","7","8","9","10"))) %>%
  arrange(isin,sdg,date,period) %>%
  group_by(isin,sdg,date) %>% 
  mutate(CAAR = cumsum(abnormal_ret)) %>%
  group_by(sdg) %>% filter(period == '10') %>%
  summarise(n = n(),
            sd = sd(CAAR),
            se = sd/sqrt(n),
            t = 1.96,
            CI=t*se
            )
      
negative_index_sdg %>% 
  group_by(sdg) %>% 
  summarise(
  sum = sum(AAR)) %>% 
  left_join(n_negative, by = "sdg") %>%
  ggplot(
    aes(x = sdg, y = sum, color= sdg,group = sdg, fill = sdg)) + 
  geom_bar(stat="identity") +
  geom_errorbar( aes(x=sdg, ymin=sum-CI, ymax=sum+CI), colour = "orange", width=0.5, alpha=0.8, size=0.7) + 
  scale_y_continuous(name ="Abnormal return",
                     labels = scales::percent,
                     breaks = c(-0.08,-0.06,-0.04,-0.02,0,0.02,0.04)) +
  theme_bw() +
  theme(legend.title = element_blank(),
        legend.key.size = unit(0.5, 'cm'),
        axis.text.x = element_text(angle=45))
ggsave("ST_negative_sdg_bar.png")




```


