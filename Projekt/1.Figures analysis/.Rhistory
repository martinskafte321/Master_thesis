ESG_risk_category == "Negligible" ~ "Low",
TRUE ~ ESG_risk_category)) %>%
filter(!ESG_risk_category %in% c('No data','Severe','Negligible')) %>% na.omit()
long_term_data_monthly <- data_monthly %>%
left_join(ESG_RR, by ="isin") %>% filter(ESG_risk_category == 'High') %>%
transmute(date,isin,MKT_CAP, free_float_mkt_cap,
ret = W_RETURN,
norm_positive_sum = sentiment_positive_count - sdg_not_relevant_positive_count,
norm_negative_sum = sentiment_negative_count - sdg_not_relevant_negative_count,
) %>%
group_by(isin) %>%
transmute(date,isin,ret,MKT_CAP,free_float_mkt_cap,
norm_positive_sum = replace_na(norm_positive_sum,0),
norm_negative_sum = replace_na(norm_negative_sum,0),
roll_mean = across(!c(date,ret,MKT_CAP,free_float_mkt_cap),
~ rollmean(.x, k = y, fill = NA, align = "right"))) %>%
unnest(roll_mean,names_sep = "_") %>% arrange(isin) %>%
group_by(isin) %>%
mutate(
roll_mean_positive = na_if(roll_mean_norm_positive_sum, 0),
roll_mean_negative = na_if(roll_mean_norm_negative_sum, 0),
positive_threshold = mean(roll_mean_positive,na.rm = TRUE) + z*sd(roll_mean_positive,na.rm = TRUE),
negative_threshold = mean(roll_mean_negative,na.rm = TRUE) + 2*sd(roll_mean_negative,na.rm = TRUE)
) %>%
group_by(date,isin) %>%
# Make sure that we only calculate the cutoff value of periods with actual observations.
mutate(
neg_event =
case_when(roll_mean_positive > positive_threshold & roll_mean_positive > 10 & roll_mean_positive > 2*roll_mean_norm_negative_sum
~ 1,
TRUE ~ 0)
)
# Add lagged values of the events to sort whether an event has happened in the last X months.
for (i in 1:12) {
long_term_data_monthly[paste0("-",i)] <- long_term_data_monthly %>% group_by(isin) %>% transmute(t = lag(neg_event,i)) %>% ungroup() %>% select(-isin)
}
long_term_data_positive = long_term_data_monthly %>% select(date,isin,ret,MKT_CAP,free_float_mkt_cap,contains("-")) %>%
pivot_longer(!c(date,isin,ret,MKT_CAP,free_float_mkt_cap), names_to = "period", values_to = "event") %>%
mutate(period = as.numeric(period)) %>%
filter(event == '1') %>%
# Remove duplicate rows of the returns in case one ISIN pops up on several dates.
group_by(date,isin) %>% distinct(ret, .keep_all = TRUE)
long_term_data_M_positive = long_term_data_positive %>%
# Only include the last 1 months:
filter(period >= -i) %>%
group_by(date) %>%
summarise(
ret = weighted.mean(ret,free_float_mkt_cap),
#ret = mean(ret),
n = n_distinct(isin)) %>%
left_join(eu_5factors_monthly, by = "date")
model = lm(ret - RF ~ 1 + mkt_excess_ret + SMB + HML + RMW + CMA, weights = n, data = long_term_data_M_positive)
summary(model)
library(lmtest)
library(sandwich)
bptest(model)
coeftest(model, vcov = vcovHC(model, type = 'HC0'))
# STOXX 600 Europe index
sxxp_index_daily <- read.csv("C:/Users/Marti/OneDrive - University of Copenhagen/KU/Speciale/Data behandling/STOXX_600_INDEX.csv",
sep = ",") %>%
transmute(date = as.Date(Date, format = "%m/%d/%Y"),
mkt_excess = as.numeric(gsub('%','',Change..))/100)
# Sentiment and stock data merged together with daily observations
data_daily <- read.csv("C:/Users/Marti/OneDrive - University of Copenhagen/KU/Speciale/Data behandling/data_daily.csv", sep = ",")  %>%
mutate(date = as.Date(date)) %>% select(-X)
ESG_RR <- read.csv("C:/Users/Marti/OneDrive - University of Copenhagen/KU/Speciale/Data behandling/ESG_ratings.csv") %>%
select("isin" = ISIN,ESG_risk_category) %>%
mutate(ESG_risk_category =
case_when(
ESG_risk_category == "Severe" ~ "High",
ESG_risk_category == "Negligible" ~ "Low",
TRUE ~ ESG_risk_category)) %>%
filter(!ESG_risk_category %in% c('No data','Severe','Negligible')) %>% na.omit()
# STOXX 600 Europe index
sxxp_index_daily <- read.csv("C:/Users/Marti/OneDrive - University of Copenhagen/KU/Speciale/Data behandling/STOXX_600_INDEX.csv",
sep = ",") %>%
transmute(date = as.Date(Date, format = "%m/%d/%Y"),
mkt_excess = as.numeric(gsub('%','',Change..))/100)
# Sentiment and stock data merged together with daily observations
data_daily <- read.csv("C:/Users/Marti/OneDrive - University of Copenhagen/KU/Speciale/Data behandling/data_daily.csv", sep = ",")  %>%
mutate(date = as.Date(date)) %>% select(-X)
ESG_RR <- read.csv("C:/Users/Marti/OneDrive - University of Copenhagen/KU/Speciale/Data behandling/ESG_ratings.csv") %>%
select("isin" = ISIN,ESG_risk_category) %>%
mutate(ESG_risk_category =
case_when(
ESG_risk_category == "Severe" ~ "High",
ESG_risk_category == "Negligible" ~ "Low",
TRUE ~ ESG_risk_category)) %>%
filter(!ESG_risk_category %in% c('No data','Severe','Negligible')) %>% na.omit()
library(readxl)
DataForAllocationKopi <- read_excel("C:/Users/Marti/Downloads/DataForAllocationKopi.xlsx")
View(DataForAllocationKopi)
DataForAllocationKopi
stop = 386
DataForAllocationKopi <- read_excel("C:/Users/Marti/Downloads/DataForAllocationKopi.xlsx")
DataForAllocationKopi
short_term_data_daily = data_daily %>%
mutate(date = as.Date(date)) %>%
right_join(sxxp_index_daily %>% select(date, mkt_excess), by = "date")
betas <- read.csv("C:/Users/Marti/OneDrive - University of Copenhagen/KU/Speciale/Data behandling/nested_daily_for_capm_sxxp.csv", sep = ",") %>%
select(-X) %>%
mutate(date = as.Date(date))
short_term_data <- betas %>%
left_join(short_term_data_daily, by = c("date","isin")) %>%
group_by(isin) %>%
mutate(
pred_ret = alpha + beta*mkt_excess,
abnormal_ret = W_RETURN - pred_ret,
norm_positive_sum = sentiment_positive_count - sdg_not_relevant_positive_count,
norm_negative_sum = sentiment_negative_count - sdg_not_relevant_negative_count
) %>%
select(-c(beta,alpha,pred_ret,sdg_not_relevant_positive_count,sdg_not_relevant_negative_count))
short_term_data <- betas %>%
left_join(short_term_data_daily, by = c("date","isin")) %>%
group_by(isin) %>%
mutate(
pred_ret = alpha + beta*mkt_excess,
abnormal_ret = W_RETURN - pred_ret,
norm_positive_sum = sentiment_positive_count - sdg_not_relevant_positive_count,
norm_negative_sum = sentiment_negative_count - sdg_not_relevant_negative_count
) %>%
select(-c(beta,alpha,pred_ret,sdg_not_relevant_positive_count,sdg_not_relevant_negative_count))
for (i in 1:10) {
short_term_data[paste0("-",i)] <- short_term_data %>% group_by(isin) %>% transmute(t = lag(abnormal_ret,i)) %>% ungroup() %>% select(-isin)
short_term_data[paste0("+",i)] <- short_term_data %>% group_by(isin) %>% transmute(t = lead(abnormal_ret,i)) %>% ungroup() %>% select(-isin)
short_term_data[paste0("neg_event_-",i)] <- short_term_data %>% group_by(isin) %>% transmute(l = lag(norm_negative_sum,i)) %>% ungroup() %>% select(-isin)
short_term_data[paste0("neg_event_+",i)] <- short_term_data %>% group_by(isin) %>% transmute(l = lead(norm_negative_sum,i)) %>% ungroup() %>% select(-isin)
short_term_data[paste0("pos_event_-",i)] <- short_term_data %>% group_by(isin) %>% transmute(l = lag(norm_positive_sum,i)) %>% ungroup() %>% select(-isin)
short_term_data[paste0("pos_event_+",i)] <- short_term_data %>% group_by(isin) %>% transmute(l = lead(norm_positive_sum,i)) %>% ungroup() %>% select(-isin)
}
short_term_data <- betas %>%
left_join(short_term_data_daily, by = c("date","isin")) %>%
group_by(isin) %>%
mutate(
pred_ret = alpha + beta*mkt_excess,
abnormal_ret = W_RETURN - pred_ret,
norm_positive_sum = sentiment_positive_count - sdg_not_relevant_positive_count,
norm_negative_sum = sentiment_negative_count - sdg_not_relevant_negative_count
) %>%
select(-c(beta,alpha,pred_ret,sdg_not_relevant_positive_count,sdg_not_relevant_negative_count))
for (i in 1:10) {
short_term_data[paste0("-",i)] <- short_term_data %>% group_by(isin) %>% transmute(t = lag(abnormal_ret,i)) %>% ungroup() %>% select(-isin)
short_term_data[paste0("+",i)] <- short_term_data %>% group_by(isin) %>% transmute(t = lead(abnormal_ret,i)) %>% ungroup() %>% select(-isin)
short_term_data[paste0("neg_event_-",i)] <- short_term_data %>% group_by(isin) %>% transmute(l = lag(norm_negative_sum,i)) %>% ungroup() %>% select(-isin)
short_term_data[paste0("neg_event_+",i)] <- short_term_data %>% group_by(isin) %>% transmute(l = lead(norm_negative_sum,i)) %>% ungroup() %>% select(-isin)
short_term_data[paste0("pos_event_-",i)] <- short_term_data %>% group_by(isin) %>% transmute(l = lag(norm_positive_sum,i)) %>% ungroup() %>% select(-isin)
short_term_data[paste0("pos_event_+",i)] <- short_term_data %>% group_by(isin) %>% transmute(l = lead(norm_positive_sum,i)) %>% ungroup() %>% select(-isin)
}
short_term_data_event = short_term_data %>%
group_by(isin) %>%
mutate(
norm_positive_sum = na_if(norm_positive_sum, 0),
norm_negative_sum = na_if(norm_negative_sum, 0),
positive_threshold = mean(norm_positive_sum,na.rm = TRUE) + 1*sd(norm_positive_sum,na.rm = TRUE),
negative_threshold = mean(norm_negative_sum,na.rm = TRUE) + 1*sd(norm_negative_sum,na.rm = TRUE)
) %>%
rename("0" = abnormal_ret) %>%
select(-c("W_RETURN","mkt_excess",
#"positive_threshold","negative_threshold","norm_positive_sum","norm_negative_sum",
"sentiment_negative_count","sentiment_positive_count",
#"roll_mean_norm_negative_sum","roll_mean_norm_positive_sum", "roll_sum_norm_negative_sum","roll_sum_norm_positive_sum"
)) %>%
group_by(date,isin) %>%
# Make sure that we only calculate the cutoff value of periods with actual observations.
mutate(pos_event =
case_when(norm_positive_sum > positive_threshold & norm_positive_sum > 10 & norm_positive_sum > 2*norm_negative_sum ~ 1,
TRUE ~ 0),
neg_event =
case_when(norm_negative_sum > negative_threshold & norm_negative_sum > 10 & norm_negative_sum > 1*norm_positive_sum ~ 1,
TRUE ~ 0)
)
negative_index = short_term_data_event %>%
select(date,isin,MKT_CAP,"0",contains("-"),contains("+"),neg_event) %>%
select(-c(contains("pos_event_"),contains("neg_event_"))) %>%
filter(neg_event == 1) %>%
select(-neg_event) %>%
pivot_longer(!c(date,isin,MKT_CAP), names_to = "type", values_to = "value") %>%
na.omit(value)
short_term_data_event
colnames(short_term_data_event)
colnames(negative_index)
negative_index
negative_index %>% left_join(ESG_RR, by =isin)
negative_index %>% left_join(ESG_RR, by ="isin")
negative_index %>% left_join(ESG_RR, by ="isin") %>% filter(type = '0')
negative_index %>% left_join(ESG_RR, by ="isin") %>% filter(type == '0')
short_term_data_event = short_term_data %>%
group_by(isin) %>%
mutate(
norm_positive_sum = na_if(norm_positive_sum, 0),
norm_negative_sum = na_if(norm_negative_sum, 0),
positive_threshold = mean(norm_positive_sum,na.rm = TRUE) + 1*sd(norm_positive_sum,na.rm = TRUE),
negative_threshold = mean(norm_negative_sum,na.rm = TRUE) + 1*sd(norm_negative_sum,na.rm = TRUE)
) %>%
rename("0" = abnormal_ret) %>%
select(-c("W_RETURN","mkt_excess",
#"positive_threshold","negative_threshold","norm_positive_sum","norm_negative_sum",
"sentiment_negative_count","sentiment_positive_count",
#"roll_mean_norm_negative_sum","roll_mean_norm_positive_sum", "roll_sum_norm_negative_sum","roll_sum_norm_positive_sum"
)) %>%
group_by(date,isin) %>%
# Make sure that we only calculate the cutoff value of periods with actual observations.
mutate(pos_event =
case_when(norm_positive_sum > positive_threshold & norm_positive_sum > 10 & norm_positive_sum > 2*norm_negative_sum ~ 1,
TRUE ~ 0),
neg_event =
case_when(norm_negative_sum > negative_threshold & norm_negative_sum > 10 & norm_negative_sum > 2*norm_positive_sum ~ 1,
TRUE ~ 0)
)
negative_index = short_term_data_event %>%
select(date,isin,MKT_CAP,"0",contains("-"),contains("+"),neg_event) %>%
select(-c(contains("pos_event_"),contains("neg_event_"))) %>%
filter(neg_event == 1) %>%
select(-neg_event) %>%
pivot_longer(!c(date,isin,MKT_CAP), names_to = "type", values_to = "value") %>%
na.omit(value)
negative_index %>% left_join(ESG_RR, by ="isin") %>% filter(type == '0')
negative_index %>% left_join(ESG_RR, by ="isin") %>% filter(type == '0') %>% filter(ESG_risk_category == 'Low')
negative_index %>% left_join(ESG_RR, by ="isin") %>% filter(type == '0') %>% filter(ESG_risk_category == 'Mediumn')
negative_index %>% left_join(ESG_RR, by ="isin") %>% filter(type == '0') %>% filter(ESG_risk_category == 'Medium')
negative_index %>% left_join(ESG_RR, by ="isin") %>% filter(type == '0') %>% filter(ESG_risk_category == 'Low') %>% arrange(value)
negative_index_events_mean = short_term_data_event %>%
select(date,isin,neg_event,norm_negative_sum, contains("neg_event")) %>%
filter(neg_event == 1) %>%
rename('0' = norm_negative_sum) %>%
select(-neg_event) %>%
pivot_longer(!c(date,isin), names_to = "type", values_to = "amount") %>%
mutate_at("type", str_replace, "neg_event_", "") %>%
group_by(isin, date)
negative_index_events = negative_index_events_mean %>%
left_join(negative_index_events_mean %>% filter(type == '0') %>% select(isin,date,"mean" = amount), by = c("isin","date")) %>%
mutate(amount = ifelse(is.na(amount), 0, amount)) %>%
mutate(relative_events = amount/mean)
negative_index_all = negative_index %>%
left_join(negative_index_events %>% select(isin,date,type,relative_events), by = c("isin","date","type")) %>%
mutate(type = factor(type, levels = c("-10", "-9","-8","-7","-6","-5","-4","-3","-2","-1",
"0", "+1", "+2","+3","+4","+5","+6","+7","+8","+9","+10"))) %>%
arrange(isin,date,type) %>%
group_by(isin,date)
negative_index_all
negative_index_10 = negative_index_all %>%
left_join(ESG_RR, by = "isin") %>%
mutate(csum = cumsum(value))
negative_index_10
negative_index_10 %>% filter(type == '-10')
negative_index_10 %>% filter(type == '-10') %>% filter(ESG_risk_category =='Low')
negative_index_10 %>% filter(type == '-10') %>% filter(ESG_risk_category =='Low') %>% arrange(value)
negative_index_10 %>% filter(type == '-10') %>% filter(ESG_risk_category =='Low') %>% arrange(csum)
negative_index_10 %>% filter(type == '10') %>% filter(ESG_risk_category =='Low') %>% arrange(csum)
negative_index_10 %>% filter(type == '+10') %>% filter(ESG_risk_category =='Low') %>% arrange(csum)
-3.481820e-01
negative_index_10 %>% filter(type == '+10') %>% filter(ESG_risk_category =='Low') %>% arrange(csum) %>% summarise(weighted.mean(csum,MKT_CAP))
negative_index_10 %>% filter(type == '+10') %>% filter(ESG_risk_category =='Low') %>% arrange(csum) %>% ungroup() %>% summarise(weighted.mean(csum,MKT_CAP))
negative_index_10 %>% filter(type == '+10') %>% filter(ESG_risk_category =='Low') %>% arrange(csum)
negative_index_10 = negative_index_all %>%
left_join(ESG_RR, by = "isin") %>%
mutate(csum = cumsum(value)) %>%
group_by(type,ESG_risk_category) %>% na.omit() %>%
summarise(
rel_events = mean(relative_events, na.rm = TRUE),
AAR = weighted.mean(value,MKT_CAP),
n = n(),
#CAAR = weighted.mean(csum,MKT_CAP),
CAAR = mean(csum),
SE_AAR = sd(value, na.rm = TRUE)/sqrt(n()),
SE_CAAR = sd(csum, na.rm = TRUE)/sqrt(n())
)
negative = negative_index_10 %>%
transmute("Relative # events" = rel_events/100, type, ESG_risk_category
,AAR,CAAR) %>%
pivot_longer(!c(type,ESG_risk_category), names_to = "metric", values_to = "ret") %>%
left_join(
negative_index_10 %>% select(type,ESG_risk_category, "AAR" = SE_AAR, "CAAR" = SE_CAAR) %>%
pivot_longer(!c(type,ESG_risk_category), names_to = "metric", values_to = "SE"), by = c("metric","type","ESG_risk_category")
) %>%
mutate(
low = ret - 1.96*SE,
high = ret + 1.96*SE
)
negative %>% filter(metric == 'CAAR') %>% mutate(ESG_risk_category = factor(ESG_risk_category, levels = c("Low", "Medium","High"))) %>%
group_by(ESG_risk_category) %>%
ggplot(aes(x = type, y = ret,colour = ESG_risk_category, group = ESG_risk_category)) +
geom_ribbon(aes(ymin = low, ymax = high, fill = ESG_risk_category),
alpha=0.1, linetype="dashed", show.legend = FALSE) +
geom_line(linewidt=1) +
theme_bw() +
theme(legend.title = element_blank(),
legend.position="top",
legend.direction = "horizontal") +
scale_y_continuous(name ="Abnormal return",
breaks = pretty_breaks(),
labels = scales::percent) +
scale_x_discrete(name = "Relative time", breaks = c("-10","-5","0","+5","+10"))
knitr::opts_chunk$set(echo = TRUE)
# Load packages:
library(tidyverse)
library(lubridate)
library(readxl)
library(lmtest)
library(timetk)
library(dplyr)
library(zoo)
library(furrr)
library(ggplot2)
library(ggpubr)
library(xtable)
library(purrr)
library(stringr)
library(magrittr)
library(BSDA)
library(scales)
library(generics)
source("functions.R")
# Data connection to get STOXX 600 Europe sentiment and stock data. Joined on stock data, so there will be NA's in the sentiment.
# Sentiment and stock data merged together with weekly observations
data_monthly <- read.csv("C:/Users/Marti/OneDrive - University of Copenhagen/KU/Speciale/Data behandling/all_data_month.csv", sep = ",") %>%
mutate(date = as.Date(date)) %>% select(date,isin, MKT_CAP,free_float_mkt_cap,W_RETURN, sentiment_negative_count,sentiment_positive_count,sdg_not_relevant_negative_count, sdg_not_relevant_positive_count)
# In the Fama French dataset, the variable "mkt_excess_ret" is created from the Bloomberg data as a market cap-weighted index.
eu_3factors_monthly = read.csv("C:/Users/Marti/OneDrive - University of Copenhagen/KU/Speciale/Data behandling/eu_3factors_monthly.csv", sep = ",") %>%
na.omit() %>% select(-X,-w_ret) %>%
mutate(date = as.Date(date)) %>%
filter(date >= '2018-01-01')
eu_5factors_monthly = read.csv("C:/Users/Marti/OneDrive - University of Copenhagen/KU/Speciale/Data behandling/eu_5factors_monthly.csv", sep = ",") %>%
na.omit() %>% select(-X) %>%
mutate(date = as.Date(date)) %>%
filter(date >= '2018-01-01')
rolling_means = list(1)
SDs = list(1)
emptylist_neg_1 = list()
emptylist_neg_2 = list()
for (y in 1:length(rolling_means)) {
for (z in 1:length(SDs)) {
long_term_data_monthly <- data_monthly %>%
left_join(ESG_RR, by ="isin") %>% filter(ESG_risk_category == 'Low') %>%
transmute(date,isin,MKT_CAP, free_float_mkt_cap,
ret = W_RETURN,
norm_positive_sum = sentiment_positive_count - sdg_not_relevant_positive_count,
norm_negative_sum = sentiment_negative_count - sdg_not_relevant_negative_count,
) %>%
group_by(isin) %>%
transmute(date,isin,ret,MKT_CAP,free_float_mkt_cap,
norm_positive_sum = replace_na(norm_positive_sum,0),
norm_negative_sum = replace_na(norm_negative_sum,0),
roll_mean = across(!c(date,ret,MKT_CAP,free_float_mkt_cap),
~ rollmean(.x, k = y, fill = NA, align = "right"))) %>%
unnest(roll_mean,names_sep = "_") %>% arrange(isin) %>%
group_by(isin) %>%
mutate(
roll_mean_positive = na_if(roll_mean_norm_positive_sum, 0),
roll_mean_negative = na_if(roll_mean_norm_negative_sum, 0),
positive_threshold = mean(roll_mean_positive,na.rm = TRUE) + z*sd(roll_mean_positive,na.rm = TRUE),
negative_threshold = mean(roll_mean_negative,na.rm = TRUE) + z*sd(roll_mean_negative,na.rm = TRUE)
) %>%
group_by(date,isin) %>%
# Make sure that we only calculate the cutoff value of periods with actual observations.
mutate(
neg_event =
case_when(roll_mean_negative > negative_threshold & roll_mean_negative > 5 #& roll_mean_negative > 0.5*roll_mean_norm_positive_sum
~ 1,
TRUE ~ 0)
)
############################
# Negative events:
############################
# Add lagged values of the events to sort whether an event has happened in the last X months.
for (i in 1:12) {
long_term_data_monthly[paste0("-",i)] <- long_term_data_monthly %>% group_by(isin) %>% transmute(t = lag(neg_event,i)) %>% ungroup() %>% select(-isin)
}
long_term_data_negative = long_term_data_monthly %>% select(date,isin,ret,MKT_CAP,free_float_mkt_cap,contains("-")) %>%
pivot_longer(!c(date,isin,ret,MKT_CAP,free_float_mkt_cap), names_to = "period", values_to = "event") %>%
mutate(period = as.numeric(period)) %>%
filter(event == '1') %>%
# Remove duplicate rows of the returns in case one ISIN pops up on several dates.
group_by(date,isin) %>% distinct(ret, .keep_all = TRUE)
# x Month portfolio returns:
list = list(1,4,8,12)
alpha_negative <- data.frame(matrix(nrow=4, ncol=6))
colnames(alpha_negative)<-c("Alpha","t","p","r","N","model")
for (x in 1:length(list)) {
i = list[[x]]
long_term_data_M_negative = long_term_data_negative %>%
# Only include the last 1 months:
filter(period >= -i) %>%
group_by(date) %>%
summarise(
ret = weighted.mean(ret,free_float_mkt_cap),
#ret = mean(ret),
n = n_distinct(isin)) %>%
left_join(eu_5factors_monthly, by = "date")
# Calculate alpha of portfolios:
alpha_M_negative = long_term_data_M_negative %>%
summarise(alpha = tidy(lm(ret - RF ~ 1 + mkt_excess_ret + SMB + HML + RMW + CMA, weights = n))$estimate[1],
t = tidy(lm(ret - RF ~ 1 + mkt_excess_ret + SMB + HML + RMW + CMA, weights = n))$statistic[1],
p = tidy(lm(ret - RF ~ 1 + mkt_excess_ret + SMB + HML + RMW + CMA, weights = n))$p.value[1],
r = glance(lm(ret - RF ~ 1 + mkt_excess_ret + SMB + HML + RMW + CMA, weights = n))$r.squared,
N = mean(n)) %>%
mutate(model = paste0(i,"M_",y,"_",z))
alpha_negative[x,] = alpha_M_negative
}
emptylist_neg_1[[z]] = alpha_negative
}
emptylist_neg_2[[y]] = emptylist_neg_1
}
long_term_data_monthly <- data_monthly %>%
# left_join(ESG_RR, by ="isin") %>% filter(ESG_risk_category == 'Low') %>%
transmute(date,isin,MKT_CAP, free_float_mkt_cap,
ret = W_RETURN,
norm_positive_sum = sentiment_positive_count - sdg_not_relevant_positive_count,
norm_negative_sum = sentiment_negative_count - sdg_not_relevant_negative_count,
) %>%
group_by(isin) %>%
transmute(date,isin,ret,MKT_CAP,free_float_mkt_cap,
norm_positive_sum = replace_na(norm_positive_sum,0),
norm_negative_sum = replace_na(norm_negative_sum,0),
roll_mean = across(!c(date,ret,MKT_CAP,free_float_mkt_cap),
~ rollmean(.x, k = y, fill = NA, align = "right"))) %>%
unnest(roll_mean,names_sep = "_") %>% arrange(isin) %>%
group_by(isin) %>%
mutate(
roll_mean_positive = na_if(roll_mean_norm_positive_sum, 0),
roll_mean_negative = na_if(roll_mean_norm_negative_sum, 0),
positive_threshold = mean(roll_mean_positive,na.rm = TRUE) + z*sd(roll_mean_positive,na.rm = TRUE),
negative_threshold = mean(roll_mean_negative,na.rm = TRUE) + z*sd(roll_mean_negative,na.rm = TRUE)
) %>%
group_by(date,isin) %>%
# Make sure that we only calculate the cutoff value of periods with actual observations.
mutate(
neg_event =
case_when(roll_mean_negative > negative_threshold & roll_mean_negative > 5 #& roll_mean_negative > 0.5*roll_mean_norm_positive_sum
~ 1,
TRUE ~ 0)
)
emptylist_neg_2
alpha_negative
rolling_means = list(1)
SDs = list(1)
emptylist_neg_1 = list()
emptylist_neg_2 = list()
for (y in 1:length(rolling_means)) {
for (z in 1:length(SDs)) {
long_term_data_monthly <- data_monthly %>%
# left_join(ESG_RR, by ="isin") %>% filter(ESG_risk_category == 'Low') %>%
transmute(date,isin,MKT_CAP, free_float_mkt_cap,
ret = W_RETURN,
norm_positive_sum = sentiment_positive_count - sdg_not_relevant_positive_count,
norm_negative_sum = sentiment_negative_count - sdg_not_relevant_negative_count,
) %>%
group_by(isin) %>%
transmute(date,isin,ret,MKT_CAP,free_float_mkt_cap,
norm_positive_sum = replace_na(norm_positive_sum,0),
norm_negative_sum = replace_na(norm_negative_sum,0),
roll_mean = across(!c(date,ret,MKT_CAP,free_float_mkt_cap),
~ rollmean(.x, k = y, fill = NA, align = "right"))) %>%
unnest(roll_mean,names_sep = "_") %>% arrange(isin) %>%
group_by(isin) %>%
mutate(
roll_mean_positive = na_if(roll_mean_norm_positive_sum, 0),
roll_mean_negative = na_if(roll_mean_norm_negative_sum, 0),
positive_threshold = mean(roll_mean_positive,na.rm = TRUE) + z*sd(roll_mean_positive,na.rm = TRUE),
negative_threshold = mean(roll_mean_negative,na.rm = TRUE) + z*sd(roll_mean_negative,na.rm = TRUE)
) %>%
group_by(date,isin) %>%
# Make sure that we only calculate the cutoff value of periods with actual observations.
mutate(
neg_event =
case_when(roll_mean_negative > negative_threshold & roll_mean_negative > 5 #& roll_mean_negative > 0.5*roll_mean_norm_positive_sum
~ 1,
TRUE ~ 0)
)
############################
# Negative events:
############################
# Add lagged values of the events to sort whether an event has happened in the last X months.
for (i in 1:12) {
long_term_data_monthly[paste0("-",i)] <- long_term_data_monthly %>% group_by(isin) %>% transmute(t = lag(neg_event,i)) %>% ungroup() %>% select(-isin)
}
long_term_data_negative = long_term_data_monthly %>% select(date,isin,ret,MKT_CAP,free_float_mkt_cap,contains("-")) %>%
pivot_longer(!c(date,isin,ret,MKT_CAP,free_float_mkt_cap), names_to = "period", values_to = "event") %>%
mutate(period = as.numeric(period)) %>%
filter(event == '1') %>%
# Remove duplicate rows of the returns in case one ISIN pops up on several dates.
group_by(date,isin) %>% distinct(ret, .keep_all = TRUE)
# x Month portfolio returns:
list = list(1,4,8,12)
alpha_negative <- data.frame(matrix(nrow=4, ncol=6))
colnames(alpha_negative)<-c("Alpha","t","p","r","N","model")
for (x in 1:length(list)) {
i = list[[x]]
long_term_data_M_negative = long_term_data_negative %>%
# Only include the last 1 months:
filter(period >= -i) %>%
group_by(date) %>%
summarise(
ret = weighted.mean(ret,free_float_mkt_cap),
#ret = mean(ret),
n = n_distinct(isin)) %>%
left_join(eu_5factors_monthly, by = "date")
# Calculate alpha of portfolios:
alpha_M_negative = long_term_data_M_negative %>%
summarise(alpha = tidy(lm(ret - RF ~ 1 + mkt_excess_ret + SMB + HML + RMW + CMA, weights = n))$estimate[1],
t = tidy(lm(ret - RF ~ 1 + mkt_excess_ret + SMB + HML + RMW + CMA, weights = n))$statistic[1],
p = tidy(lm(ret - RF ~ 1 + mkt_excess_ret + SMB + HML + RMW + CMA, weights = n))$p.value[1],
r = glance(lm(ret - RF ~ 1 + mkt_excess_ret + SMB + HML + RMW + CMA, weights = n))$r.squared,
N = mean(n)) %>%
mutate(model = paste0(i,"M_",y,"_",z))
alpha_negative[x,] = alpha_M_negative
}
emptylist_neg_1[[z]] = alpha_negative
}
emptylist_neg_2[[y]] = emptylist_neg_1
}
emptylist_neg_2
