summarise(
rel_events = mean(relative_events, na.rm = TRUE),
AAR = weighted.mean(value,MKT_CAP),
CAAR = weighted.mean(csum, MKT_CAP),
n = n(),
SE_AAR = sd(value, na.rm = TRUE)/sqrt(n()),
SE_CAAR = sd(csum, na.rm = TRUE)/sqrt(n())
)
negative_index_10
short_term_data_event = short_term_data %>%
group_by(isin) %>%
mutate(
norm_positive_sum = na_if(norm_positive_sum, 0),
norm_negative_sum = na_if(norm_negative_sum, 0),
positive_threshold = mean(norm_positive_sum,na.rm = TRUE) + 3*sd(norm_positive_sum,na.rm = TRUE),
negative_threshold = mean(norm_negative_sum,na.rm = TRUE) + 3*sd(norm_negative_sum,na.rm = TRUE)
) %>%
rename("0" = abnormal_ret) %>%
select(-c("W_RETURN","mkt_excess",
#"positive_threshold","negative_threshold","norm_positive_sum","norm_negative_sum",
"sentiment_negative_count","sentiment_positive_count",
#"roll_mean_norm_negative_sum","roll_mean_norm_positive_sum", "roll_sum_norm_negative_sum","roll_sum_norm_positive_sum"
)) %>%
group_by(date,isin) %>%
# Make sure that we only calculate the cutoff value of periods with actual observations.
mutate(pos_event =
case_when(norm_positive_sum > positive_threshold & norm_positive_sum > 10 & norm_positive_sum > 2*norm_negative_sum ~ 1,
TRUE ~ 0),
neg_event =
case_when(norm_negative_sum > negative_threshold & norm_negative_sum > 10 & norm_negative_sum > 2*norm_positive_sum ~ 1,
TRUE ~ 0)
)
negative_index = short_term_data_event %>%
select(date,isin,MKT_CAP,"0",contains("-"),contains("+"),neg_event) %>%
select(-c(contains("pos_event_"),contains("neg_event_"))) %>%
filter(neg_event == 1) %>%
select(-neg_event) %>%
pivot_longer(!c(date,isin,MKT_CAP), names_to = "type", values_to = "value") %>%
na.omit(value)
negative_index_events_mean = short_term_data_event %>%
select(date,isin,neg_event,norm_negative_sum, contains("neg_event")) %>%
filter(neg_event == 1) %>%
rename('0' = norm_negative_sum) %>%
select(-neg_event) %>%
pivot_longer(!c(date,isin), names_to = "type", values_to = "amount") %>%
mutate_at("type", str_replace, "neg_event_", "") %>%
group_by(isin, date)
negative_index_events = negative_index_events_mean %>%
left_join(negative_index_events_mean %>% filter(type == '0') %>% select(isin,date,"mean" = amount), by = c("isin","date")) %>%
mutate(amount = ifelse(is.na(amount), 0, amount)) %>%
mutate(relative_events = amount/mean)
negative_index_all = negative_index %>%
left_join(negative_index_events %>% select(isin,date,type,relative_events), by = c("isin","date","type")) %>%
mutate(type = factor(type, levels = c("-10", "-9","-8","-7","-6","-5","-4","-3","-2","-1",
"0", "+1", "+2","+3","+4","+5","+6","+7","+8","+9","+10"))) %>%
arrange(isin,date,type) %>%
group_by(isin,date)
negative_index_all %>% group_by(type) %>% summarise(mean(MKT_CAP))
negative_index_all
negative_index_10 = negative_index_all %>%
mutate(csum = cumsum(value)) %>%
group_by(type) %>%
summarise(
rel_events = mean(relative_events, na.rm = TRUE),
AAR = weighted.mean(value,MKT_CAP),
CAAR = weighted.mean(csum, MKT_CAP),
n = n(),
SE_AAR = sd(value, na.rm = TRUE)/sqrt(n()),
SE_CAAR = sd(csum, na.rm = TRUE)/sqrt(n())
)
negative_index_10
56377225023*7.445
negative_index_10 %>% select(type,AAR,CAAR,rel_events) %>%
transmute("Relative # events" = rel_events/100,type,AAR,CAAR) %>%
pivot_longer(!c(type), names_to = "metric", values_to = "ret") %>%
left_join(
negative_index_10 %>% select(type, "AAR" = SE_AAR, "CAAR" = SE_CAAR) %>%
pivot_longer(!c(type), names_to = "metric", values_to ="SE"), by = c("metric","type")) %>%
mutate(
low = ret - 1.96*SE,
high = ret + 1.96*SE
) %>%
group_by(metric) %>%
ggplot(aes(x = type, y = ret,colour = metric, group = metric)) +
geom_bar(data = ~ filter(.x, metric %in% c("Relative # events")),
aes(x=type, y=ret), stat = "identity",color="grey", fill="grey",
alpha=0.05, width = 1) +
geom_ribbon(data = ~ filter(.x, metric %in% c("CAAR", "AAR")),
aes(ymin = low, ymax = high, fill = metric),
alpha=0.3, linetype="dashed", show.legend = FALSE) +
geom_line(data = ~ filter(.x, metric %in% c("CAAR", "AAR")),
size=1) +
theme_bw() +
theme(legend.title = element_blank(),
legend.position="top",
legend.direction = "horizontal") +
scale_y_continuous(name ="Abnormal return",
breaks = pretty_breaks(n = 8),
labels = scales::percent,
sec.axis=sec_axis(
breaks = c(0,0.5,1),
~.*100,name="Relative events")) +
scale_x_discrete(name = "Relative time",breaks=c("-10","-5","0","+5","+10"))
short_term_data_event = short_term_data %>%
group_by(isin) %>%
mutate(
norm_positive_sum = na_if(norm_positive_sum, 0),
norm_negative_sum = na_if(norm_negative_sum, 0),
positive_threshold = mean(norm_positive_sum,na.rm = TRUE) + 1*sd(norm_positive_sum,na.rm = TRUE),
negative_threshold = mean(norm_negative_sum,na.rm = TRUE) + 1*sd(norm_negative_sum,na.rm = TRUE)
) %>%
rename("0" = abnormal_ret) %>%
select(-c("W_RETURN","mkt_excess",
#"positive_threshold","negative_threshold","norm_positive_sum","norm_negative_sum",
"sentiment_negative_count","sentiment_positive_count",
#"roll_mean_norm_negative_sum","roll_mean_norm_positive_sum", "roll_sum_norm_negative_sum","roll_sum_norm_positive_sum"
)) %>%
group_by(date,isin) %>%
# Make sure that we only calculate the cutoff value of periods with actual observations.
mutate(pos_event =
case_when(norm_positive_sum > positive_threshold & norm_positive_sum > 10 & norm_positive_sum > 2*norm_negative_sum ~ 1,
TRUE ~ 0),
neg_event =
case_when(norm_negative_sum > negative_threshold & norm_negative_sum > 10 & norm_negative_sum > 2*norm_positive_sum ~ 1,
TRUE ~ 0)
)
# Positive
positive_index = short_term_data_event %>%
select(date,isin,MKT_CAP,"0",contains("-"),contains("+"),pos_event) %>%
select(-c(contains("pos_event_"),contains("neg_event_"))) %>%
filter(pos_event == 1) %>%
select(-pos_event) %>%
pivot_longer(!c(date,isin,MKT_CAP), names_to = "type", values_to = "value") %>%
na.omit(value)
positive_index_events_mean = short_term_data_event %>% select(date,isin,pos_event,norm_positive_sum, contains("pos_event")) %>%
filter(pos_event == 1) %>%
rename('0' = norm_positive_sum) %>%
select(-pos_event) %>%
pivot_longer(!c(date,isin), names_to = "type", values_to = "amount") %>%
mutate_at("type", str_replace, "pos_event_", "") %>%
group_by(isin, date)
positive_index_events = positive_index_events_mean %>%
left_join(positive_index_events_mean %>% filter(type == '0') %>% select(isin,date,"mean" = amount), by = c("isin","date")) %>%
mutate(amount = ifelse(is.na(amount), 0, amount)) %>%
mutate(relative_events = amount/mean)
positive_index_all = positive_index %>%
left_join(positive_index_events %>% select(isin,date,type,relative_events), by = c("isin","date","type")) %>%
mutate(type = factor(type, levels = c("-10", "-9","-8","-7","-6","-5","-4","-3","-2","-1",
"0", "+1", "+2","+3","+4","+5","+6","+7","+8","+9","+10"))) %>%
arrange(isin,date,type) %>%
group_by(isin,date)
negative_index = short_term_data_event %>%
select(date,isin,MKT_CAP,"0",contains("-"),contains("+"),neg_event) %>%
select(-c(contains("pos_event_"),contains("neg_event_"))) %>%
filter(neg_event == 1) %>%
select(-neg_event) %>%
pivot_longer(!c(date,isin,MKT_CAP), names_to = "type", values_to = "value") %>%
na.omit(value)
negative_index_events_mean = short_term_data_event %>%
select(date,isin,neg_event,norm_negative_sum, contains("neg_event")) %>%
filter(neg_event == 1) %>%
rename('0' = norm_negative_sum) %>%
select(-neg_event) %>%
pivot_longer(!c(date,isin), names_to = "type", values_to = "amount") %>%
mutate_at("type", str_replace, "neg_event_", "") %>%
group_by(isin, date)
negative_index_events = negative_index_events_mean %>%
left_join(negative_index_events_mean %>% filter(type == '0') %>% select(isin,date,"mean" = amount), by = c("isin","date")) %>%
mutate(amount = ifelse(is.na(amount), 0, amount)) %>%
mutate(relative_events = amount/mean)
negative_index_all = negative_index %>%
left_join(negative_index_events %>% select(isin,date,type,relative_events), by = c("isin","date","type")) %>%
mutate(type = factor(type, levels = c("-10", "-9","-8","-7","-6","-5","-4","-3","-2","-1",
"0", "+1", "+2","+3","+4","+5","+6","+7","+8","+9","+10"))) %>%
arrange(isin,date,type) %>%
group_by(isin,date)
positive_index_10 = positive_index_all %>%
mutate(csum = cumsum(value)) %>%
group_by(type) %>%
summarise(
rel_events = mean(relative_events, na.rm = TRUE),
AAR = weighted.mean(value,MKT_CAP),
CAAR = weighted.mean(csum, MKT_CAP),
SE_AAR = sd(value, na.rm = TRUE)/sqrt(n()),
n = n(),
SE_CAAR = sd(csum, na.rm = TRUE)/sqrt(n())
)
negative_index_10 = negative_index_all %>%
mutate(csum = cumsum(value)) %>%
group_by(type) %>%
summarise(
rel_events = mean(relative_events, na.rm = TRUE),
AAR = weighted.mean(value,MKT_CAP),
CAAR = weighted.mean(csum, MKT_CAP),
n = n(),
SE_AAR = sd(value, na.rm = TRUE)/sqrt(n()),
SE_CAAR = sd(csum, na.rm = TRUE)/sqrt(n())
)
positive_index_10 %>% select(type,AAR,CAAR,rel_events) %>%
transmute("Relative # events" = rel_events/100,type,AAR,CAAR) %>%
pivot_longer(!c(type), names_to = "metric", values_to = "ret") %>%
left_join(
positive_index_10 %>% select(type, "AAR" = SE_AAR, "CAAR" = SE_CAAR) %>%
pivot_longer(!c(type), names_to = "metric", values_to = "SE"), by = c("metric","type")
) %>%
mutate(
low = ret - 1.96*SE,
high = ret + 1.96*SE
) %>%
group_by(metric) %>%
ggplot(aes(x = type, y = ret,colour = metric, group = metric)) +
geom_bar(data = ~ filter(.x, metric %in% c("Relative # events")),
aes(x=type, y=ret), stat = "identity", color="grey", fill="grey",
alpha=0.05, width = 1) +
geom_ribbon(data = ~ filter(.x, metric %in% c("CAAR", "AAR")),
aes(ymin = low, ymax = high, fill = metric),
alpha=0.3, linetype="dashed", show.legend = FALSE) +
geom_line(data = ~ filter(.x, metric %in% c("CAAR", "AAR")),
size=1) +
theme_bw() +
theme(legend.title = element_blank(),
legend.position="top",
legend.direction = "horizontal") +
scale_y_continuous(name ="Abnormal return",
breaks = pretty_breaks(),
labels = scales::percent,
sec.axis=sec_axis(
breaks = c(0,0.5,1),
~.*100,name="Relative events")) +
scale_x_discrete(name = "Relative time",breaks=c("-10","-5","0","+5","+10"))
positive_index_10 = positive_index_all %>%
mutate(csum = cumsum(value)) %>%
group_by(type) %>%
summarise(
rel_events = mean(relative_events, na.rm = TRUE),
AAR = mean(value),
CAAR = mean(csum),
SE_AAR = sd(value, na.rm = TRUE)/sqrt(n()),
n = n(),
SE_CAAR = sd(csum, na.rm = TRUE)/sqrt(n())
)
positive_index_10 %>% select(type,AAR,CAAR,rel_events) %>%
transmute("Relative # events" = rel_events/100,type,AAR,CAAR) %>%
pivot_longer(!c(type), names_to = "metric", values_to = "ret") %>%
left_join(
positive_index_10 %>% select(type, "AAR" = SE_AAR, "CAAR" = SE_CAAR) %>%
pivot_longer(!c(type), names_to = "metric", values_to = "SE"), by = c("metric","type")
) %>%
mutate(
low = ret - 1.96*SE,
high = ret + 1.96*SE
) %>%
group_by(metric) %>%
ggplot(aes(x = type, y = ret,colour = metric, group = metric)) +
geom_bar(data = ~ filter(.x, metric %in% c("Relative # events")),
aes(x=type, y=ret), stat = "identity", color="grey", fill="grey",
alpha=0.05, width = 1) +
geom_ribbon(data = ~ filter(.x, metric %in% c("CAAR", "AAR")),
aes(ymin = low, ymax = high, fill = metric),
alpha=0.3, linetype="dashed", show.legend = FALSE) +
geom_line(data = ~ filter(.x, metric %in% c("CAAR", "AAR")),
size=1) +
theme_bw() +
theme(legend.title = element_blank(),
legend.position="top",
legend.direction = "horizontal") +
scale_y_continuous(name ="Abnormal return",
breaks = pretty_breaks(),
labels = scales::percent,
sec.axis=sec_axis(
breaks = c(0,0.5,1),
~.*100,name="Relative events")) +
scale_x_discrete(name = "Relative time",breaks=c("-10","-5","0","+5","+10"))
negative_index_10 = negative_index_all %>%
mutate(csum = cumsum(value)) %>%
group_by(type) %>%
summarise(
rel_events = mean(relative_events, na.rm = TRUE),
AAR = weighted.mean(value,MKT_CAP),
CAAR = weighted.mean(csum, MKT_CAP),
n = n(),
SE_AAR = sd(value, na.rm = TRUE)/sqrt(n()),
SE_CAAR = sd(csum, na.rm = TRUE)/sqrt(n())
)
negative_index_10 %>% select(type,AAR,CAAR,rel_events) %>%
transmute("Relative # events" = rel_events/100,type,AAR,CAAR) %>%
pivot_longer(!c(type), names_to = "metric", values_to = "ret") %>%
left_join(
negative_index_10 %>% select(type, "AAR" = SE_AAR, "CAAR" = SE_CAAR) %>%
pivot_longer(!c(type), names_to = "metric", values_to ="SE"), by = c("metric","type")) %>%
mutate(
low = ret - 1.96*SE,
high = ret + 1.96*SE
) %>%
group_by(metric) %>%
ggplot(aes(x = type, y = ret,colour = metric, group = metric)) +
geom_bar(data = ~ filter(.x, metric %in% c("Relative # events")),
aes(x=type, y=ret), stat = "identity",color="grey", fill="grey",
alpha=0.05, width = 1) +
geom_ribbon(data = ~ filter(.x, metric %in% c("CAAR", "AAR")),
aes(ymin = low, ymax = high, fill = metric),
alpha=0.3, linetype="dashed", show.legend = FALSE) +
geom_line(data = ~ filter(.x, metric %in% c("CAAR", "AAR")),
size=1) +
theme_bw() +
theme(legend.title = element_blank(),
legend.position="top",
legend.direction = "horizontal") +
scale_y_continuous(name ="Abnormal return",
breaks = pretty_breaks(n = 8),
labels = scales::percent,
sec.axis=sec_axis(
breaks = c(0,0.5,1),
~.*100,name="Relative events")) +
scale_x_discrete(name = "Relative time",breaks=c("-10","-5","0","+5","+10"))
t = negative_index_10 %>% select(type,AAR,CAAR,rel_events) %>%
transmute("Relative # events" = rel_events/100,type,AAR,CAAR) %>%
pivot_longer(!c(type), names_to = "metric", values_to = "ret") %>%
left_join(
negative_index_10 %>% select(type, "AAR" = SE_AAR, "CAAR" = SE_CAAR) %>%
pivot_longer(!c(type), names_to = "metric", values_to ="SE"), by = c("metric","type")) %>%
mutate(
low = ret - 1.96*SE,
high = ret + 1.96*SE
)
t %>% write.csv("Short_term_negative_news")
t %>% write.csv("Short_term_negative_news.csv")
positive_index_10 %>% select(type,AAR,CAAR,rel_events) %>%
transmute("Relative # events" = rel_events/100,type,AAR,CAAR) %>%
pivot_longer(!c(type), names_to = "metric", values_to = "ret") %>%
left_join(
positive_index_10 %>% select(type, "AAR" = SE_AAR, "CAAR" = SE_CAAR) %>%
pivot_longer(!c(type), names_to = "metric", values_to = "SE"), by = c("metric","type")
) %>%
mutate(
low = ret - 1.96*SE,
high = ret + 1.96*SE
) %>%
group_by(metric) %>%
ggplot(aes(x = type, y = ret,colour = metric, group = metric)) +
geom_bar(data = ~ filter(.x, metric %in% c("Relative # events")),
aes(x=type, y=ret), stat = "identity", color="grey", fill="grey",
alpha=0.05, width = 1) +
geom_ribbon(data = ~ filter(.x, metric %in% c("CAAR", "AAR")),
aes(ymin = low, ymax = high, fill = metric),
alpha=0.3, linetype="dashed", show.legend = FALSE) +
geom_line(data = ~ filter(.x, metric %in% c("CAAR", "AAR")),
size=1) +
theme_bw() +
theme(legend.title = element_blank(),
legend.position="top",
legend.direction = "horizontal") +
scale_y_continuous(name ="Abnormal return",
breaks = pretty_breaks(),
labels = scales::percent,
sec.axis=sec_axis(
breaks = c(0,0.5,1),
~.*100,name="Relative events")) +
scale_x_discrete(name = "Relative time",breaks=c("-10","-5","0","+5","+10"))
r = positive_index_10 %>% select(type,AAR,CAAR,rel_events) %>%
transmute("Relative # events" = rel_events/100,type,AAR,CAAR) %>%
pivot_longer(!c(type), names_to = "metric", values_to = "ret") %>%
left_join(
positive_index_10 %>% select(type, "AAR" = SE_AAR, "CAAR" = SE_CAAR) %>%
pivot_longer(!c(type), names_to = "metric", values_to = "SE"), by = c("metric","type")
) %>%
mutate(
low = ret - 1.96*SE,
high = ret + 1.96*SE
)
r %>% write.csv("Short_term_positive_news.csv")
negative_index_10 = negative_index_all %>%
left_join(ESG_RR, by = "isin") %>%
mutate(csum = cumsum(value)) %>%
group_by(type) %>% na.omit() %>%
summarise(
rel_events = mean(relative_events, na.rm = TRUE),
AAR = weighted.mean(value,MKT_CAP),
n = n(),
CAAR = weighted.mean(csum,MKT_CAP),
SE_AAR = sd(value, na.rm = TRUE)/sqrt(n()),
SE_CAAR = sd(csum, na.rm = TRUE)/sqrt(n())
)
negative = negative_index_10 %>%
transmute("Relative # events" = rel_events/100, type, ESG_risk_category
,AAR,CAAR) %>%
pivot_longer(!c(type,ESG_risk_category), names_to = "metric", values_to = "ret") %>%
left_join(
negative_index_10 %>% select(type,ESG_risk_category, "AAR" = SE_AAR, "CAAR" = SE_CAAR) %>%
pivot_longer(!c(type,ESG_risk_category), names_to = "metric", values_to = "SE"), by = c("metric","type","ESG_risk_category")
) %>%
mutate(
low = ret - 1.96*SE,
high = ret + 1.96*SE
)
negative_index_10
negative_index_10 = negative_index_all %>%
left_join(ESG_RR, by = "isin") %>%
mutate(csum = cumsum(value)) %>%
group_by(type) %>% na.omit() %>%
summarise(
rel_events = mean(relative_events, na.rm = TRUE),
AAR = weighted.mean(value,MKT_CAP),
n = n(),
CAAR = weighted.mean(csum,MKT_CAP),
SE_AAR = sd(value, na.rm = TRUE)/sqrt(n()),
SE_CAAR = sd(csum, na.rm = TRUE)/sqrt(n())
)
negative_index_10
negative_index_all
negative_index_10 = negative_index_all %>%
left_join(ESG_RR, by = "isin") %>%
mutate(csum = cumsum(value)) %>%
group_by(type,ESG_risk_category) %>% na.omit() %>%
summarise(
rel_events = mean(relative_events, na.rm = TRUE),
AAR = weighted.mean(value,MKT_CAP),
n = n(),
CAAR = weighted.mean(csum,MKT_CAP),
SE_AAR = sd(value, na.rm = TRUE)/sqrt(n()),
SE_CAAR = sd(csum, na.rm = TRUE)/sqrt(n())
)
negative_index_10
negative = negative_index_10 %>%
transmute("Relative # events" = rel_events/100, type, ESG_risk_category
,AAR,CAAR) %>%
pivot_longer(!c(type,ESG_risk_category), names_to = "metric", values_to = "ret") %>%
left_join(
negative_index_10 %>% select(type,ESG_risk_category, "AAR" = SE_AAR, "CAAR" = SE_CAAR) %>%
pivot_longer(!c(type,ESG_risk_category), names_to = "metric", values_to = "SE"), by = c("metric","type","ESG_risk_category")
) %>%
mutate(
low = ret - 1.96*SE,
high = ret + 1.96*SE
)
negative %>% filter(metric == 'CAAR') %>% mutate(ESG_risk_category = factor(ESG_risk_category, levels = c("Low", "Medium","High"))) %>%
group_by(ESG_risk_category) %>%
ggplot(aes(x = type, y = ret,colour = ESG_risk_category, group = ESG_risk_category)) +
geom_ribbon(aes(ymin = low, ymax = high, fill = ESG_risk_category),
alpha=0.1, linetype="dashed", show.legend = FALSE) +
geom_line(size=1) +
theme_bw() +
theme(legend.title = element_blank(),
legend.position="top",
legend.direction = "horizontal") +
scale_y_continuous(name ="Abnormal return",
breaks = pretty_breaks(),
labels = scales::percent) +
scale_x_discrete(name = "Relative time", breaks = c("-10","-5","0","+5","+10"))
negative %>% write.csv("ST_negative_ESG.csv")
negative_index_10
negative_index_10 %>% filter(ESG_risk_category == 'high')
negative_index_10 %>% filter(ESG_risk_category == 'High')
negative_index_all %>%
left_join(ESG_RR, by = "isin") %>%
mutate(csum = cumsum(value)) %>% filter(ESG_risk_category == 'High')
negative_index_all %>%
left_join(ESG_RR, by = "isin") %>%
mutate(csum = cumsum(value)) %>% filter(ESG_risk_category == 'High') %>% filter(type == 'type') %>% summarise(weighted.mean(value,MKT_CAP))
negative_index_all %>%
left_join(ESG_RR, by = "isin") %>%
mutate(csum = cumsum(value)) %>% filter(ESG_risk_category == 'High') %>% filter(type == '10') %>% summarise(weighted.mean(value,MKT_CAP))
negative_index_all %>%
left_join(ESG_RR, by = "isin") %>%
mutate(csum = cumsum(value)) %>% filter(ESG_risk_category == 'High') %>% filter(type == '+10') %>% summarise(weighted.mean(value,MKT_CAP))
negative_index_all %>%
left_join(ESG_RR, by = "isin") %>%
mutate(csum = cumsum(value)) %>% filter(ESG_risk_category == 'High') %>% ungroup() %>% filter(type == '+10') %>% summarise(weighted.mean(value,MKT_CAP))
negative_index_all %>%
left_join(ESG_RR, by = "isin") %>%
mutate(csum = cumsum(value)) %>% filter(ESG_risk_category == 'High') %>% ungroup() %>% filter(type == '+10') %>% summarise(weighted.mean(csum,MKT_CAP))
negative
negative_index_all %>%
left_join(ESG_RR, by = "isin") %>%
mutate(csum = cumsum(value)) %>% filter(ESG_risk_category == 'High') %>% ungroup() %>% filter(type == '+10') %>% summarise(weighted.mean(csum,MKT_CAP))
betas
betas <- read.csv("C:/Users/Marti/OneDrive - University of Copenhagen/KU/Speciale/Data behandling/nested_daily_for_capm_sxxp.csv", sep = ",") %>%
select(-X) %>%
mutate(date = as.Date(date))
betas
short_term_data_sdg <- betas %>%
left_join(short_term_data_daily, by = c("date","isin")) %>%
group_by(isin) %>%
mutate(
pred_ret = alpha + beta*mkt_excess,
abnormal_ret = W_RETURN - pred_ret
) %>%
select(-c(beta,alpha,pred_ret,sdg_not_relevant_positive_count,sdg_not_relevant_negative_count))
# STOXX 600 Europe index
sxxp_index_daily <- read.csv("C:/Users/Marti/OneDrive - University of Copenhagen/KU/Speciale/Data behandling/STOXX_600_INDEX.csv",
sep = ",") %>%
transmute(date = as.Date(Date, format = "%m/%d/%Y"),
mkt_excess = as.numeric(gsub('%','',Change..))/100)
# Sentiment and stock data merged together with daily observations
data_daily <- read.csv("C:/Users/Marti/OneDrive - University of Copenhagen/KU/Speciale/Data behandling/data_daily.csv", sep = ",")  %>%
mutate(date = as.Date(date)) %>% select(-X)
short_term_data_daily = data_daily %>%
mutate(date = as.Date(date)) %>%
right_join(sxxp_index_daily %>% select(date, mkt_excess), by = "date")
betas <- read.csv("C:/Users/Marti/OneDrive - University of Copenhagen/KU/Speciale/Data behandling/nested_daily_for_capm_sxxp.csv", sep = ",") %>%
select(-X) %>%
mutate(date = as.Date(date))
short_term_data <- betas %>%
left_join(short_term_data_daily, by = c("date","isin")) %>%
group_by(isin) %>%
mutate(
pred_ret = alpha + beta*mkt_excess,
abnormal_ret = W_RETURN - pred_ret,
norm_positive_sum = sentiment_positive_count - sdg_not_relevant_positive_count,
norm_negative_sum = sentiment_negative_count - sdg_not_relevant_negative_count
) %>%
select(-c(beta,alpha,pred_ret,sdg_not_relevant_positive_count,sdg_not_relevant_negative_count))
